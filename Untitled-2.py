# -*- coding: utf-8 -*-
"""
Questionnaire Simulation System (Adapted for American Participants)
- Reads subject background Excel (Gender/Age/Highest Education Level only)
- Calls Alibaba Cloud Qwen-plus API for simulated responses
- Retains target dimensions: Emotional Abuse, Emotional Neglect, Supervisor Support, Personal Mastery, Perceived Constraints, Job insecurity
- Features: Random question order + No same dimension for 4 consecutive times + API retry + Failure handling + Fatal error stop & save
- Automatically parses scores, handles reverse coding, outputs standardized Excel results
"""
import os
import re
#import random
import time
import pandas as pd
from pathlib import Path
from openai import OpenAI
from datetime import datetime
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# ---------------- Core Configuration (Adjust as Needed) ----------------
# API Configuration (Alibaba Cloud Qwen)
DASHSCOPE_API_KEY = "sk-51b0406a9d884aa0aa99627d50a61329"  # Your API key
BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"  # Beijing region (no modification needed)
MODEL_NAME = "qwen-plus"  # Fixed model name

# File Path Configuration
SUBJECT_BACKGROUND_FILE = r"C:\Users\15896\Desktop\æˆ‘çš„ä»£ç æ–‡ä»¶\æ¨¡æ‹Ÿäººå˜é‡ä»¥åŠç›¸åº”æ°´å¹³.xlsx"  # Subject background Excel path
OUTPUT_DIR = r"C:\Users\15896\Desktop\æˆ‘çš„ä»£ç æ–‡ä»¶"  # Result output directory

MAX_TOKENS = 512  # Maximum length per response
TEMPERATURE = 0.7  # Response diversity (0.7 = close to real human)
#MAX_CONSECUTIVE_SAME_DIM = 3  # Max 3 consecutive questions from same dimension (no 4+)
API_RETRY_TIMES = 3  # API retry times (3 times by default)
API_RETRY_DELAY = 2  # Initial retry delay (2 seconds, exponential backoff)

# DEBUG: æœ¬åœ°æµ‹è¯•å¼€å…³ï¼ˆTrue=ä½¿ç”¨æ¨¡æ‹Ÿ LLM å“åº”å¹¶è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•å—è¯•è€…æ–‡ä»¶ï¼‰
DEBUG_MODE = False

# Global flag: Fatal API error (arrearage/access denied)
FATAL_API_ERROR = False
FATAL_ERROR_MSG = ""

# Initialize API Client (OpenAI-compatible format)
client = OpenAI(
    api_key=DASHSCOPE_API_KEY,
    base_url=BASE_URL,
)

# ---------------- Questionnaire Items (Target Dimensions, English Version) ----------------
QUESTIONS = [
    # 1. æƒ…æ„Ÿè™å¾…ï¼ˆEmotional Abuseï¼‰- 5é¢˜ï¼Œ5ç‚¹è®¡åˆ† 1=Never true;5=Very often trueï¼Œæ— åå‘ï¼Œåˆ†æ•°è¶Šé«˜è™å¾…è¶Šä¸¥é‡
    {
        "question_id": "EA_1",
        "dimension": "æƒ…æ„Ÿè™å¾…",
        "stem": "People in my family called me things like â€œstupid,â€ â€œlazy,â€ or â€œugly.â€ (When I was growing up)",
        "coding": "1=Never true; 2=Rarely true; 3=Sometimes true; 4=Often true; 5=Very often true",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "EA_2",
        "dimension": "æƒ…æ„Ÿè™å¾…",
        "stem": "I thought that my parents wished I had never been born. (When I was growing up)",
        "coding": "1=Never true; 2=Rarely true; 3=Sometimes true; 4=Often true; 5=Very often true",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "EA_3",
        "dimension": "æƒ…æ„Ÿè™å¾…",
        "stem": "People in my family said hurtful or insulting things to me. (When I was growing up)",
        "coding": "1=Never true; 2=Rarely true; 3=Sometimes true; 4=Often true; 5=Very often true",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "EA_4",
        "dimension": "æƒ…æ„Ÿè™å¾…",
        "stem": "I felt that someone in my family hated me. (When I was growing up)",
        "coding": "1=Never true; 2=Rarely true; 3=Sometimes true; 4=Often true; 5=Very often true",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "EA_5",
        "dimension": "æƒ…æ„Ÿè™å¾…",
        "stem": "I believe that I was emotionally abused. (When I was growing up)",
        "coding": "1=Never true; 2=Rarely true; 3=Sometimes true; 4=Often true; 5=Very often true",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    # 2. æƒ…æ„Ÿå¿½è§†ï¼ˆEmotional Neglectï¼‰- 5é¢˜ï¼Œ5ç‚¹è®¡åˆ† 1=Never true;5=Very often trueï¼Œå…¨åå‘ï¼Œåˆ†æ•°è¶Šé«˜å¿½è§†è¶Šä¸¥é‡
    {
        "question_id": "EN_1",
        "dimension": "æƒ…æ„Ÿå¿½è§†",
        "stem": "There was someone in my family who helped me feel that I was important or special. (When I was growing up)",
        "coding": "1=Never true; 2=Rarely true; 3=Sometimes true; 4=Often true; 5=Very often true",
        "reverse_coded": True,
        "score_range": (1, 5)
    },
    {
        "question_id": "EN_2",
        "dimension": "æƒ…æ„Ÿå¿½è§†",
        "stem": "I felt loved. (When I was growing up)",
        "coding": "1=Never true; 2=Rarely true; 3=Sometimes true; 4=Often true; 5=Very often true",
        "reverse_coded": True,
        "score_range": (1, 5)
    },
    {
        "question_id": "EN_3",
        "dimension": "æƒ…æ„Ÿå¿½è§†",
        "stem": "People in my family looked out for each other. (When I was growing up)",
        "coding": "1=Never true; 2=Rarely true; 3=Sometimes true; 4=Often true; 5=Very often true",
        "reverse_coded": True,
        "score_range": (1, 5)
    },
    {
        "question_id": "EN_4",
        "dimension": "æƒ…æ„Ÿå¿½è§†",
        "stem": "People in my family felt close to each other. (When I was growing up)",
        "coding": "1=Never true; 2=Rarely true; 3=Sometimes true; 4=Often true; 5=Very often true",
        "reverse_coded": True,
        "score_range": (1, 5)
    },
    {
        "question_id": "EN_5",
        "dimension": "æƒ…æ„Ÿå¿½è§†",
        "stem": "My family was a source of strength and support. (When I was growing up)",
        "coding": "1=Never true; 2=Rarely true; 3=Sometimes true; 4=Often true; 5=Very often true",
        "reverse_coded": True,
        "score_range": (1, 5)
    },
    # 3. ä¸»ç®¡æ”¯æŒï¼ˆSupervisory Support Scaleï¼‰- 9é¢˜ï¼Œ5ç‚¹æå…‹ç‰¹ï¼Œæ— åå‘è®¡åˆ†ï¼Œåˆ†æ•°è¶Šé«˜æ”¯æŒåº¦è¶Šé«˜ï¼ˆåŸæœ‰æ­£ç¡®ï¼Œä¿ç•™ï¼‰
    {
        "question_id": "SS_1",
        "dimension": "ä¸»ç®¡æ”¯æŒ",
        "stem": "My supervisor takes the time to learn about my career goals and aspirations",
        "coding": "1=strongly agree; 2=agree to some extent; 3=uncertain; 4=disagree to some extent; 5=strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "SS_2",
        "dimension": "ä¸»ç®¡æ”¯æŒ",
        "stem": "My supervisor cares about whether or not I achieve my goals",
        "coding": "1=strongly agree; 2=agree to some extent; 3=uncertain; 4=disagree to some extent; 5=strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "SS_3",
        "dimension": "ä¸»ç®¡æ”¯æŒ",
        "stem": "My supervisor keeps me informed about different career opportunities for me in the organization",
        "coding": "1=strongly agree; 2=agree to some extent; 3=uncertain; 4=disagree to some extent; 5=strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "SS_4",
        "dimension": "ä¸»ç®¡æ”¯æŒ",
        "stem": "My supervisor makes sure I get the credit when I accomplish something substantial on the job",
        "coding": "1=strongly agree; 2=agree to some extent; 3=uncertain; 4=disagree to some extent; 5=strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "SS_5",
        "dimension": "ä¸»ç®¡æ”¯æŒ",
        "stem": "My supervisor gives me helpful feedback about my performance",
        "coding": "1=strongly agree; 2=agree to some extent; 3=uncertain; 4=disagree to some extent; 5=strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "SS_6",
        "dimension": "ä¸»ç®¡æ”¯æŒ",
        "stem": "My supervisor gives me helpful advice about improving my performance when I need it",
        "coding": "1=strongly agree; 2=agree to some extent; 3=uncertain; 4=disagree to some extent; 5=strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "SS_7",
        "dimension": "ä¸»ç®¡æ”¯æŒ",
        "stem": "My supervisor supports my attempts to acquire additional training or education to further my career",
        "coding": "1=strongly agree; 2=agree to some extent; 3=uncertain; 4=disagree to some extent; 5=strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "SS_8",
        "dimension": "ä¸»ç®¡æ”¯æŒ",
        "stem": "My supervisor provides assignments that give me the opportunity to develop and strengthen new skills",
        "coding": "1=strongly agree; 2=agree to some extent; 3=uncertain; 4=disagree to some extent; 5=strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "SS_9",
        "dimension": "ä¸»ç®¡æ”¯æŒ",
        "stem": "My supervisor assigns me special projects that increase my visibility in the organization",
        "coding": "1=strongly agree; 2=agree to some extent; 3=uncertain; 4=disagree to some extent; 5=strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    # 4. ä¸ªäººæŒæ§ï¼ˆPersonal Masteryï¼‰- 4é¢˜ï¼Œ7ç‚¹æå…‹ç‰¹ï¼Œåå‘è®¡åˆ†ï¼Œåˆ†æ•°è¶Šé«˜æŒæ§æ„Ÿè¶Šå¼ºï¼ˆåŸæœ‰æ­£ç¡®ï¼Œä¿ç•™ï¼‰
    {
        "question_id": "PM_1",
        "dimension": "ä¸ªäººæŒæ§",
        "stem": "I can do just about anything I really set my mind to.",
        "coding": "1=Strongly agree; 2=Somewhat agree; 3=A little agree; 4=Don't know; 5=A little disagree; 6=Somewhat disagree; 7=Strongly disagree",
        "reverse_coded": True,
        "score_range": (1, 7)
    },
    {
        "question_id": "PM_2",
        "dimension": "ä¸ªäººæŒæ§",
        "stem": "When I really want to do something, I usually find a way to succeed at it.",
        "coding": "1=Strongly agree; 2=Somewhat agree; 3=A little agree; 4=Don't know; 5=A little disagree; 6=Somewhat disagree; 7=Strongly disagree",
        "reverse_coded": True,
        "score_range": (1, 7)
    },
    {
        "question_id": "PM_3",
        "dimension": "ä¸ªäººæŒæ§",
        "stem": "Whether or not I am able to get what I want is in my own hands.",
        "coding": "1=Strongly agree; 2=Somewhat agree; 3=A little agree; 4=Don't know; 5=A little disagree; 6=Somewhat disagree; 7=Strongly disagree",
        "reverse_coded": True,
        "score_range": (1, 7)
    },
    {
        "question_id": "PM_4",
        "dimension": "ä¸ªäººæŒæ§",
        "stem": "What happens to me in the future mostly depends on me.",
        "coding": "1=Strongly agree; 2=Somewhat agree; 3=A little agree; 4=Don't know; 5=A little disagree; 6=Somewhat disagree; 7=Strongly disagree",
        "reverse_coded": True,
        "score_range": (1, 7)
    },
    # 5. æ„ŸçŸ¥çº¦æŸï¼ˆPerceived Constraintsï¼‰- 8é¢˜ï¼Œ7ç‚¹æå…‹ç‰¹ï¼Œæ— åå‘è®¡åˆ†ï¼Œåˆ†æ•°è¶Šé«˜çº¦æŸæ„Ÿè¶Šå¼ºï¼ˆåŸæœ‰æ­£ç¡®ï¼Œä¿ç•™ï¼‰
    {
        "question_id": "PC_1",
        "dimension": "æ„ŸçŸ¥çº¦æŸ",
        "stem": "There is little I can do to change the important things in my life.",
        "coding": "1=Strongly agree; 2=Somewhat agree; 3=A little agree; 4=Don't know; 5=A little disagree; 6=Somewhat disagree; 7=Strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 7)
    },
    {
        "question_id": "PC_2",
        "dimension": "æ„ŸçŸ¥çº¦æŸ",
        "stem": "I often feel helpless in dealing with the problems of life.",
        "coding": "1=Strongly agree; 2=Somewhat agree; 3=A little agree; 4=Don't know; 5=A little disagree; 6=Somewhat disagree; 7=Strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 7)
    },
    {
        "question_id": "PC_3",
        "dimension": "æ„ŸçŸ¥çº¦æŸ",
        "stem": "Other people determine most of what I can and cannot do.",
        "coding": "1=Strongly agree; 2=Somewhat agree; 3=A little agree; 4=Don't know; 5=A little disagree; 6=Somewhat disagree; 7=Strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 7)
    },
    {
        "question_id": "PC_4",
        "dimension": "æ„ŸçŸ¥çº¦æŸ",
        "stem": "What happens in my life is often beyond my control.",
        "coding": "1=Strongly agree; 2=Somewhat agree; 3=A little agree; 4=Don't know; 5=A little disagree; 6=Somewhat disagree; 7=Strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 7)
    },
    {
        "question_id": "PC_5",
        "dimension": "æ„ŸçŸ¥çº¦æŸ",
        "stem": "There are many things that interfere with what I want to do.",
        "coding": "1=Strongly agree; 2=Somewhat agree; 3=A little agree; 4=Don't know; 5=A little disagree; 6=Somewhat disagree; 7=Strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 7)
    },
    {
        "question_id": "PC_6",
        "dimension": "æ„ŸçŸ¥çº¦æŸ",
        "stem": "I have little control over the things that happen to me.",
        "coding": "1=Strongly agree; 2=Somewhat agree; 3=A little agree; 4=Don't know; 5=A little disagree; 6=Somewhat disagree; 7=Strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 7)
    },
    {
        "question_id": "PC_7",
        "dimension": "æ„ŸçŸ¥çº¦æŸ",
        "stem": "There is really no way I can solve the problems I have.",
        "coding": "1=Strongly agree; 2=Somewhat agree; 3=A little agree; 4=Don't know; 5=A little disagree; 6=Somewhat disagree; 7=Strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 7)
    },
    {
        "question_id": "PC_8",
        "dimension": "æ„ŸçŸ¥çº¦æŸ",
        "stem": "I sometimes feel I am being pushed around in my life.",
        "coding": "1=Strongly agree; 2=Somewhat agree; 3=A little agree; 4=Don't know; 5=A little disagree; 6=Somewhat disagree; 7=Strongly disagree",
        "reverse_coded": False,
        "score_range": (1, 7)
    },
    # 6. å·¥ä½œä¸å®‰å…¨æ„Ÿï¼ˆJob Insecurity Scaleï¼‰- 4é¢˜ï¼Œ5ç‚¹æå…‹ç‰¹ 1=Strongly disagree;5=Strongly agreeï¼Œç¬¬4é¢˜åå‘ï¼Œåˆ†æ•°è¶Šé«˜ä¸å®‰å…¨æ„Ÿè¶Šå¼ºï¼ˆä¿®æ­£ä¸ºé‡è¡¨ç‰ˆï¼‰
    {
        "question_id": "JI_1",
        "dimension": "å·¥ä½œä¸å®‰å…¨æ„Ÿ",
        "stem": "Chances are, I will soon lose my job.",
        "coding": "1=Strongly disagree; 2=Disagree; 3=Neither agree nor disagree; 4=Agree; 5=Strongly agree",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "JI_2",
        "dimension": "å·¥ä½œä¸å®‰å…¨æ„Ÿ",
        "stem": "I feel insecure about the future of my job.",
        "coding": "1=Strongly disagree; 2=Disagree; 3=Neither agree nor disagree; 4=Agree; 5=Strongly agree",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "JI_3",
        "dimension": "å·¥ä½œä¸å®‰å…¨æ„Ÿ",
        "stem": "I think I might lose my job in the near future.",
        "coding": "1=Strongly disagree; 2=Disagree; 3=Neither agree nor disagree; 4=Agree; 5=Strongly agree",
        "reverse_coded": False,
        "score_range": (1, 5)
    },
    {
        "question_id": "JI_4",
        "dimension": "å·¥ä½œä¸å®‰å…¨æ„Ÿ",
        "stem": "I am sure I can keep my job.",
        "coding": "1=Strongly disagree; 2=Disagree; 3=Neither agree nor disagree; 4=Agree; 5=Strongly agree",
        "reverse_coded": True,
        "score_range": (1, 5)
    }
]

# ---------------- Tool Functions ----------------
def load_subject_background(file_path):
    """Read subject background Excel, return standardized subject list"""
    print(f"Reading subject background file: {file_path}")
    try:
        df = pd.read_excel(file_path)
        required_cols = ['æ€§åˆ«', 'å¹´é¾„', 'æœ€é«˜æ•™è‚²æ°´å¹³', 'èŒä¸š', 'è¡Œä¸š', 'å®¶åº­å¹´æ€»æ”¶å…¥']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"Excel missing required columns: {', '.join(missing_cols)} (ensure header matches requirements)")
        
        # 1. ç»Ÿä¸€å¤„ç†ç¼ºå¤±å€¼ï¼šæŠŠæ–‡æœ¬ã€Œç¼ºå¤±å€¼ã€æ›¿æ¢æˆNaNï¼Œæ–¹ä¾¿åç»­è¿‡æ»¤
        df = df.replace("ç¼ºå¤±å€¼", pd.NA)
        
        # 2. å¹´é¾„åˆ—æ¸…æ´—ï¼šè½¬æ•°å€¼ç±»å‹ï¼Œè¿‡æ»¤18-75å²çš„æœ‰æ•ˆæˆå¹´è¢«è¯•
        df['å¹´é¾„'] = pd.to_numeric(df['å¹´é¾„'], errors='coerce').astype('Int64')
        df = df[(df['å¹´é¾„'] >= 18) & (df['å¹´é¾„'] <= 75)]
        
        # 3. æ–‡æœ¬åˆ—å®‰å…¨å¤„ç†ï¼šå…ˆè½¬å­—ç¬¦ä¸²ï¼Œå†strip
        text_cols = ['æ€§åˆ«', 'æœ€é«˜æ•™è‚²æ°´å¹³', 'èŒä¸š', 'è¡Œä¸š']
        for col in text_cols:
            df[col] = df[col].fillna("ä¸é€‚ç”¨").astype(str).str.strip()
        
        # 4. å®¶åº­å¹´æ”¶å…¥åˆ—ç‰¹æ®Šå¤„ç†ï¼šæ•°å€¼è½¬å­—ç¬¦ä¸²ï¼Œç¼ºå¤±å€¼ç»Ÿä¸€ä¸º"ä¸é€‚ç”¨"
        df['å®¶åº­å¹´æ€»æ”¶å…¥'] = df['å®¶åº­å¹´æ€»æ”¶å…¥'].apply(
            lambda x: f"{int(x)}" if pd.notna(x) and isinstance(x, (int, float)) else "ä¸é€‚ç”¨"
        )
        
        # 5. è¿‡æ»¤æ ¸å¿ƒå­—æ®µå…¨ç©ºçš„è¡Œ
        df = df.dropna(subset=['æ€§åˆ«', 'å¹´é¾„', 'æœ€é«˜æ•™è‚²æ°´å¹³'])
        
        # Convert to subject list
        subjects = []
        for idx, row in df.iterrows():
            subjects.append({
                "subject_id": int(row['è¢«è¯•ID']) if pd.notna(row['è¢«è¯•ID']) else idx + 1,
                "æ€§åˆ«": row['æ€§åˆ«'],
                "å¹´é¾„": row['å¹´é¾„'],
                "æœ€é«˜æ•™è‚²æ°´å¹³": row['æœ€é«˜æ•™è‚²æ°´å¹³'],
                "èŒä¸š": row['èŒä¸š'],
                "è¡Œä¸š": row['è¡Œä¸š'],
                "å®¶åº­å¹´æ€»æ”¶å…¥": row['å®¶åº­å¹´æ€»æ”¶å…¥']
            })
        
        print(f"Successfully loaded {len(subjects)} valid subjects (excluded nulls/invalid ages)")
        return subjects
    except Exception as e:
        print(f"Failed to read subject background: {str(e)}")
        import traceback
        traceback.print_exc()  
        return []

def generate_subject_prompt(subject, question):
    """Generate subject-specific prompt (English, adapted for American context)"""
    # ä¼˜åŒ–ä¸»ç®¡æ”¯æŒå¤‡æ³¨ï¼šæ ¹æ®èŒä¸šæ˜¯å¦ä¸ºç¼ºå¤±/ä¸é€‚ç”¨åˆ¤æ–­
    supervisor_note = ""
    if "ä¸»ç®¡æ”¯æŒ" in question['dimension']:
        if subject['èŒä¸š'] in ["ä¸é€‚ç”¨", "æ‹’ç»å›ç­”", "ä¸çŸ¥é“"]:
            supervisor_note = " (Note: If you don't have a supervisor or job, answer based on hypothetical work experience or common sense)"
        else:
            supervisor_note = f" (Note: Answer combined with your occupation as {subject['èŒä¸š']} in {subject['è¡Œä¸š']} industry)"
    
    # English prompt template
    prompt = f"""You are a real American citizen with the following personal background:
- Gender: {subject['æ€§åˆ«']}
- Age: {subject['å¹´é¾„']} years old
- Highest Education Level: {subject['æœ€é«˜æ•™è‚²æ°´å¹³']}
- Occupation: {subject['èŒä¸š']}
- Industry: {subject['è¡Œä¸š']}
- Annual Household Income: {subject['å®¶åº­å¹´æ€»æ”¶å…¥']}
Fully embody this role, combine American cultural background, life experiences, and true feelings to answer the following questionnaire in the first person{supervisor_note}. Response requirements:
1. Strictly select a score based on the given coding standard (only enter a number between {question['score_range'][0]}-{question['score_range'][1]});
2. Add 1-2 sentences to explain the reason after the score. The reason should match your occupation, industry, income level and American social culture, avoiding emptiness;
3. Answer naturally and colloquially, like an ordinary American chattingâ€”no formal writing or AI tone;
4. For work-related questions, answer based on your occupation, industry and career experience in the U.S.;
5. Do not reveal you are a simulated role, and never say phrases like "as an AI" or "according to the setting";
6. Only answer based on the current task, do not reference any previous responses.
Question: {question['stem']}
Coding Standard: {question['coding']}
Please answer directly without additional formatting."""
    return prompt

def map_text_to_score(text, question):
    """Map text description to score (for responses without explicit numbers)"""
    text_lower = text.lower()
    min_s, max_s = question['score_range']
    coding_type = question['coding']
    
    # 1-5 points (Never true â†’ Very often true)
    if "Never true" in coding_type:
        if any(w in text_lower for w in ["never", "never true", "not at all"]):
            return 1
        elif any(w in text_lower for w in ["rarely", "seldom"]):
            return 2
        elif any(w in text_lower for w in ["sometimes", "occasionally"]):
            return 3
        elif any(w in text_lower for w in ["often", "frequently"]):
            return 4
        elif any(w in text_lower for w in ["very often", "always", "constantly"]):
            return 5
    # 1-5 points (All the time â†’ Never)
    elif "All the time" in coding_type:
        if any(w in text_lower for w in ["all the time", "always"]):
            return 1
        elif any(w in text_lower for w in ["most of the time", "usually"]):
            return 2
        elif any(w in text_lower for w in ["sometimes", "occasionally"]):
            return 3
        elif any(w in text_lower for w in ["rarely", "seldom"]):
            return 4
        elif any(w in text_lower for w in ["never", "not at all"]):
            return 5
    # 1-7 points (Strongly agree â†’ Strongly disagree)
    elif "Strongly agree" in coding_type:
        if any(w in text_lower for w in ["strongly agree", "fully agree", "completely agree"]):
            return 1
        elif any(w in text_lower for w in ["somewhat agree", "partially agree"]):
            return 2
        elif any(w in text_lower for w in ["a little agree", "slightly agree"]):
            return 3
        elif any(w in text_lower for w in ["don't know", "unsure", "no idea"]):
            return 4
        elif any(w in text_lower for w in ["a little disagree", "slightly disagree"]):
            return 5
        elif any(w in text_lower for w in ["somewhat disagree", "partially disagree"]):
            return 6
        elif any(w in text_lower for w in ["strongly disagree", "completely disagree"]):
            return 7
    # 1-5 points (Excellent â†’ Poor)
    elif "Excellent" in coding_type:
        if any(w in text_lower for w in ["excellent", "very good", "definitely"]):
            return 1
        elif any(w in text_lower for w in ["very good", "highly likely"]):
            return 2
        elif any(w in text_lower for w in ["good", "likely"]):
            return 3
        elif any(w in text_lower for w in ["fair", "so-so", "uncertain"]):
            return 4
        elif any(w in text_lower for w in ["poor", "unlikely", "definitely not"]):
            return 5
    
    return None

@retry(
    stop=stop_after_attempt(API_RETRY_TIMES),
    wait=wait_exponential(multiplier=1, min=API_RETRY_DELAY),  # å…³é”®ï¼šmin=åˆå§‹å»¶è¿Ÿï¼Œæ›¿ä»£é”™è¯¯çš„initial/initial_delay
    retry=retry_if_exception_type(Exception),
    reraise=True
)
def call_llm(prompt):
    """Call Qwen API with retry mechanism, return raw response"""
    global FATAL_API_ERROR, FATAL_ERROR_MSG
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "user", "content": prompt}  # è¡¥å…¨ä½ ä»£ç æˆªæ–­çš„messageséƒ¨åˆ†
            ],
            max_tokens=MAX_TOKENS,
            temperature=TEMPERATURE
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        error_msg = str(e)
        if any(keyword in error_msg for keyword in ["InvalidApiKey", "Arrearage", "AccessDenied"]):
            FATAL_API_ERROR = True
            FATAL_ERROR_MSG = error_msg
        raise

# å¦‚æœå¯ç”¨ DEBUG_MODEï¼Œåˆ™è¦†ç›– call_llm ä¸ºæœ¬åœ°æ¨¡æ‹Ÿå‡½æ•°ï¼ˆä¸è°ƒç”¨å¤–éƒ¨ APIï¼‰
if 'DEBUG_MODE' in globals() and DEBUG_MODE:
    print("âš™ï¸ DEBUG_MODE å¯ç”¨ï¼šAPI è°ƒç”¨å°†è¢«æ¨¡æ‹Ÿï¼ˆæœ¬åœ°æµ‹è¯•ï¼‰")
    _mock_counter = {'c': 0}
    def _mock_call_llm(prompt):
        # åŸºäºè®¡æ•°å¾ªç¯ç”Ÿæˆ 1-5 çš„åˆ†æ•°ï¼Œä»¥ä¿è¯å¤šæ ·æ€§å’Œå¯é¢„æµ‹æ€§
        _mock_counter['c'] += 1
        score = (_mock_counter['c'] % 5) + 1
        reason = f"Mock response #{_mock_counter['c']}: simulated reason matching prompt."
        return f"{score} {reason}"
    # è¦†ç›–çœŸå®çš„ call_llmï¼ˆç”¨äºæµ‹è¯•ï¼‰
    call_llm = _mock_call_llm

def calculate_scale_scores(responses):
    scale_scores = {}
    # æŒ‰ç»´åº¦åˆ†ç»„ç»Ÿè®¡åˆ†æ•°
    dimension_groups = {}
    for resp in responses:
        dim = resp['ç»´åº¦']
        if dim not in dimension_groups:
            dimension_groups[dim] = []
        if resp['æœ€ç»ˆå¾—åˆ†'] is not None:  # ä»…ç»Ÿè®¡æœ‰æ•ˆå¾—åˆ†
            dimension_groups[dim].append(resp['æœ€ç»ˆå¾—åˆ†'])
    
    # 1. æƒ…æ„Ÿè™å¾…ï¼ˆ5é¢˜ï¼‰
    ea_scores = dimension_groups.get('æƒ…æ„Ÿè™å¾…', [])
    scale_scores['æƒ…æ„Ÿè™å¾…_æ€»åˆ†'] = sum(ea_scores) if len(ea_scores) == 5 else None
    scale_scores['æƒ…æ„Ÿè™å¾…_å¹³å‡åˆ†'] = round(sum(ea_scores)/len(ea_scores), 2) if len(ea_scores) == 5 else None
    
    # 2. æƒ…æ„Ÿå¿½è§†ï¼ˆ5é¢˜ï¼‰
    en_scores = dimension_groups.get('æƒ…æ„Ÿå¿½è§†', [])
    scale_scores['æƒ…æ„Ÿå¿½è§†_æ€»åˆ†'] = sum(en_scores) if len(en_scores) == 5 else None
    scale_scores['æƒ…æ„Ÿå¿½è§†_å¹³å‡åˆ†'] = round(sum(en_scores)/len(en_scores), 2) if len(en_scores) == 5 else None
    
    # 3. ä¸»ç®¡æ”¯æŒï¼ˆ9é¢˜ï¼‰
    ss_scores = dimension_groups.get('ä¸»ç®¡æ”¯æŒ', [])
    scale_scores['ä¸»ç®¡æ”¯æŒ_æ€»åˆ†'] = sum(ss_scores) if len(ss_scores) == 9 else None
    scale_scores['ä¸»ç®¡æ”¯æŒ_å¹³å‡åˆ†'] = round(sum(ss_scores)/len(ss_scores), 2) if len(ss_scores) == 9 else None
    
    # 4. ä¸ªäººæŒæ§ï¼ˆ4é¢˜ï¼‰
    pm_scores = dimension_groups.get('ä¸ªäººæŒæ§', [])
    scale_scores['ä¸ªäººæŒæ§_æ€»åˆ†'] = sum(pm_scores) if len(pm_scores) == 4 else None
    scale_scores['ä¸ªäººæŒæ§_å¹³å‡åˆ†'] = round(sum(pm_scores)/len(pm_scores), 2) if len(pm_scores) == 4 else None
    
    # 5. æ„ŸçŸ¥çº¦æŸï¼ˆ8é¢˜ï¼‰
    pc_scores = dimension_groups.get('æ„ŸçŸ¥çº¦æŸ', [])
    scale_scores['æ„ŸçŸ¥çº¦æŸ_æ€»åˆ†'] = sum(pc_scores) if len(pc_scores) == 8 else None
    scale_scores['æ„ŸçŸ¥çº¦æŸ_å¹³å‡åˆ†'] = round(sum(pc_scores)/len(pc_scores), 2) if len(pc_scores) == 8 else None
    
    # 6. å·¥ä½œä¸å®‰å…¨æ„Ÿï¼ˆ4é¢˜ï¼Œä¿®æ­£ä¸ºé‡è¡¨ç‰ˆï¼‰
    ji_scores = dimension_groups.get('å·¥ä½œä¸å®‰å…¨æ„Ÿ', [])
    scale_scores['å·¥ä½œä¸å®‰å…¨æ„Ÿ_æ€»åˆ†'] = sum(ji_scores) if len(ji_scores) == 4 else None
    scale_scores['å·¥ä½œä¸å®‰å…¨æ„Ÿ_å¹³å‡åˆ†'] = round(sum(ji_scores)/len(ji_scores), 2) if len(ji_scores) == 4 else None
    
    return scale_scores

# ---------------- Parse LLM Response ----------------
def parse_question_response(raw_resp, question):
    """
    Parse the LLM response to extract the score and reason.
    Returns (score, reason).
    """
    # Try to extract the first number in the valid range as the score
    min_s, max_s = question['score_range']
    # Find all numbers in the response
    numbers = re.findall(r'\d+', raw_resp)
    score = None
    for num in numbers:
        n = int(num)
        if min_s <= n <= max_s:
            score = n
            break
    # If not found, try to map text to score
    if score is None:
        score = map_text_to_score(raw_resp, question)
    # Apply reverse coding if needed
    if score is not None and question.get('reverse_coded', False):
        score = max_s + min_s - score
    # Extract reason: remove the score part from the response
    reason = raw_resp
    if score is not None:
        # Remove the score (number) from the start if present
        reason = re.sub(r'^\s*' + str(score) + r'[\s\.\,\:\-]*', '', raw_resp, count=1).strip()
    return score, reason

#def get_random_questions(original_questions):
    """Generate random question order with constraint: no same dimension for 4 consecutive times"""
    while True:
        # Create a copy to avoid modifying original list
        random_questions = original_questions.copy()
        random.shuffle(random_questions)
        
        # Check if constraint is satisfied
        valid = True
        for i in range(len(random_questions) - MAX_CONSECUTIVE_SAME_DIM):
            # Get current dimension and next 3 dimensions (total 4 consecutive)
            current_dim = random_questions[i]['dimension']
            consecutive_dims = [random_questions[j]['dimension'] for j in range(i, i + MAX_CONSECUTIVE_SAME_DIM + 1)]
            
            # If all 4 are same dimension, invalid
            if all(dim == current_dim for dim in consecutive_dims):
                valid = False
                break
        
        if valid:
            return random_questions

def save_current_results(all_results, failed_records, out_dir):
    """Save current results immediately (even if process is stopped)"""
    if all_results:
        df_out = pd.DataFrame(all_results)
        # Adjust column order for readability
        # ä¿®å¤ï¼šæ‰€æœ‰é€—å·æ”¹ä¸ºè‹±æ–‡åŠè§’ï¼Œè¡¥å…¨åˆ—ååˆ†éš”ç¬¦
        column_order = [
        "è¢«è¯•ID", "æ€§åˆ«", "å¹´é¾„", "æ•™è‚²æ°´å¹³",
        "èŒä¸š", "è¡Œä¸š", "å®¶åº­å¹´æ€»æ”¶å…¥",
        "éšæœºé¢˜ç›®åºå·", "åŸå§‹é¢˜ç›®ID", "ç»´åº¦", "é¢˜ç›®å†…å®¹ï¼ˆè‹±æ–‡ï¼‰", "è®¡åˆ†æ ‡å‡†ï¼ˆè‹±æ–‡ï¼‰", "æ˜¯å¦åå‘è®¡åˆ†",
        "åŸå§‹å“åº”ï¼ˆè‹±æ–‡ï¼‰", "æå–åˆ†æ•°", "æœ€ç»ˆå¾—åˆ†", "å›ç­”ç†ç”±ï¼ˆè‹±æ–‡ï¼‰", "ä½œç­”çŠ¶æ€",
        "æƒ…æ„Ÿè™å¾…_æ€»åˆ†", "æƒ…æ„Ÿè™å¾…_å¹³å‡åˆ†", "æƒ…æ„Ÿå¿½è§†_æ€»åˆ†", "æƒ…æ„Ÿå¿½è§†_å¹³å‡åˆ†",
        "ä¸»ç®¡æ”¯æŒ_æ€»åˆ†", "ä¸»ç®¡æ”¯æŒ_å¹³å‡åˆ†", "ä¸ªäººæŒæ§_æ€»åˆ†", "ä¸ªäººæŒæ§_å¹³å‡åˆ†",
        "æ„ŸçŸ¥çº¦æŸ_æ€»åˆ†", "æ„ŸçŸ¥çº¦æŸ_å¹³å‡åˆ†", "å·¥ä½œä¸å®‰å…¨æ„Ÿ_æ€»åˆ†", "å·¥ä½œä¸å®‰å…¨æ„Ÿ_å¹³å‡åˆ†"
        ]
        # Ensure all columns exist
        for col in column_order:
            if col not in df_out.columns:
                df_out[col] = None
        df_out = df_out[column_order]
        
        # Generate filename with timestamp (mark as interrupted)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = out_dir / f"Interrupted_Results_{timestamp}.xlsx"
        
        # Save Excel
        df_out.to_excel(output_file, index=False, engine='openpyxl')
        print(f"\n Current results saved to: {output_file}")
        
        # Save failed records if any
        if failed_records:
            df_failed = pd.DataFrame(failed_records)
            failed_file = out_dir / f"Interrupted_Failed_Records_{timestamp}.xlsx"
            df_failed.to_excel(failed_file, index=False, engine='openpyxl')
            print(f" Failed records saved to: {failed_file}")
        
        # Save fatal error info if exists
        if FATAL_API_ERROR:
            error_info = pd.DataFrame([{
                "ç»ˆæ­¢åŸå› ": "APIè‡´å‘½é”™è¯¯",
                "é”™è¯¯è¯¦æƒ…": FATAL_ERROR_MSG,
                "ç»ˆæ­¢æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "å·²å¤„ç†è¢«è¯•æ•°": len(set([r['è¢«è¯•ID'] for r in all_results])),
                "å·²å¤„ç†é¢˜ç›®æ•°": len(all_results)
            }])
            error_file = out_dir / f"Fatal_Error_Info_{timestamp}.xlsx"
            error_info.to_excel(error_file, index=False, engine='openpyxl')
            print(f"âœ… Fatal error info saved to: {error_file}")
    else:
        print("\nâš ï¸ No results to save (all_results is empty)")

# ---------------- Main Process ----------------
def main():
    global FATAL_API_ERROR
    # 1. Load subject background
    subjects = load_subject_background(SUBJECT_BACKGROUND_FILE)
    if not subjects:
        print("No valid subjects, program exited")
        return
    
    # 2. Create output directory
    out_dir = Path(OUTPUT_DIR)
    out_dir.mkdir(parents=True, exist_ok=True)
    
    # 3. Iterate over subjects to generate responses
    all_results = []
    failed_records = []  # Record failed questions for later check
    
    try:
        for subject in subjects:
            # Check fatal error: stop processing new subjects
            if FATAL_API_ERROR:
                break
            
            print(f"\nProcessing subject {subject['subject_id']} ({subject['æ€§åˆ«']}, {subject['å¹´é¾„']} years old)...")
            subject_responses = []
            
            # Get random question order (satisfy dimension constraint)
            #random_question_list = get_random_questions(QUESTIONS)
            #print(f"  Generated random question order (total {len(random_question_list)} questions)")
            # Use original question order (no randomization)
            random_question_list = QUESTIONS  # ç›´æ¥ä½¿ç”¨åŸå§‹QUESTIONSåˆ—è¡¨çš„é¡ºåº
            print(f"  Using original question order (total {len(random_question_list)} questions)")
            
            # Answer questions in random order
            for idx, question in enumerate(random_question_list, start=1):
                # Check fatal error: stop processing new questions for current subject
                if FATAL_API_ERROR:
                    break
                
                print(f"  Answering question {idx}/{len(random_question_list)}: {question['question_id']} (Dimension: {question['dimension']})")
                try:
                    # Generate prompt
                    prompt = generate_subject_prompt(subject, question)
                    # The following block is likely intended for exception handling, so wrap it in except
                    # Simulate API call and response parsing (replace with actual API call logic)
                    raw_resp = call_llm(prompt)
                    score, reason = parse_question_response(raw_resp, question)
                    subject_responses.append({
                        "è¢«è¯•ID": subject['subject_id'],
                        "æ€§åˆ«": subject['æ€§åˆ«'],
                        "èŒä¸š": subject['èŒä¸š'],
                        "è¡Œä¸š": subject['è¡Œä¸š'],
                        "å®¶åº­å¹´æ€»æ”¶å…¥": subject['å®¶åº­å¹´æ€»æ”¶å…¥'],
                        "å¹´é¾„": subject['å¹´é¾„'],
                        "æ•™è‚²æ°´å¹³": subject['æœ€é«˜æ•™è‚²æ°´å¹³'],
                        "éšæœºé¢˜ç›®åºå·": idx,
                        "åŸå§‹é¢˜ç›®ID": question['question_id'],
                        "ç»´åº¦": question['dimension'],
                        "é¢˜ç›®å†…å®¹ï¼ˆè‹±æ–‡ï¼‰": question['stem'],
                        "è®¡åˆ†æ ‡å‡†ï¼ˆè‹±æ–‡ï¼‰": question['coding'],
                        "æ˜¯å¦åå‘è®¡åˆ†": question['reverse_coded'],
                        "åŸå§‹å“åº”ï¼ˆè‹±æ–‡ï¼‰": raw_resp,
                        "æå–åˆ†æ•°": score,
                        "æœ€ç»ˆå¾—åˆ†": score,
                        "å›ç­”ç†ç”±ï¼ˆè‹±æ–‡ï¼‰": reason,
                        "ä½œç­”çŠ¶æ€": "æˆåŠŸ" if score is not None else "å¤±è´¥"
                    })
                except Exception as error_msg:
                    # Add to failed records
                    subject_responses.append({
                        "è¢«è¯•ID": subject['subject_id'],
                        "æ€§åˆ«": subject['æ€§åˆ«'],
                        "èŒä¸š": subject['èŒä¸š'],
                        "è¡Œä¸š": subject['è¡Œä¸š'],
                        "å®¶åº­å¹´æ€»æ”¶å…¥": subject['å®¶åº­å¹´æ€»æ”¶å…¥'],
                        "å¹´é¾„": subject['å¹´é¾„'],
                        "æ•™è‚²æ°´å¹³": subject['æœ€é«˜æ•™è‚²æ°´å¹³'],
                        "éšæœºé¢˜ç›®åºå·": idx,
                        "åŸå§‹é¢˜ç›®ID": question['question_id'],
                        "ç»´åº¦": question['dimension'],
                        "é¢˜ç›®å†…å®¹ï¼ˆè‹±æ–‡ï¼‰": question['stem'],
                        "è®¡åˆ†æ ‡å‡†ï¼ˆè‹±æ–‡ï¼‰": question['coding'],
                        "æ˜¯å¦åå‘è®¡åˆ†": question['reverse_coded'],
                        "åŸå§‹å“åº”ï¼ˆè‹±æ–‡ï¼‰": f"API_CALL_FAILED: {error_msg}",
                        "æå–åˆ†æ•°": None,
                        "æœ€ç»ˆå¾—åˆ†": None,
                        "å›ç­”ç†ç”±ï¼ˆè‹±æ–‡ï¼‰": "API call failed",
                        "ä½œç­”çŠ¶æ€": "å¤±è´¥"
                    })
                    failed_records.append({
                        "è¢«è¯•ID": subject['subject_id'],
                        "é¢˜ç›®ID": question['question_id'],
                        "é”™è¯¯åŸå› ": str(error_msg)
                    })
            
            # Calculate dimension scores for the subject
            scale_scores = calculate_scale_scores(subject_responses)
            # Merge dimension scores into each response
            for resp in subject_responses:
                resp.update(scale_scores)
            # Add to total results
            all_results.extend(subject_responses)
    
    except KeyboardInterrupt:
        print("\nğŸ”´ Program interrupted by user (Ctrl+C)")
    finally:
        # Save current results no matter why process stopped
        save_current_results(all_results, failed_records, out_dir)
        if FATAL_API_ERROR:
            print(f"\nğŸ”´ Program terminated due to fatal API error: {FATAL_ERROR_MSG}")
            print("ğŸ”´ Please resolve the API issue (e.g., recharge Alibaba Cloud account) and restart the program.")
        print("\nâœ… Program exited safely (all current results saved)")

if __name__ == "__main__":
    # Ensure required dependency 'tenacity' is available
    try:
        from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
    except ImportError:
        print("Installing required package 'tenacity'...")
        os.system("pip install tenacity")
        from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

    # è‹¥ä¸ºæœ¬åœ°è°ƒè¯•æ¨¡å¼ï¼Œç”Ÿæˆä¸€ä¸ªå°çš„å—è¯•è€… Excel ä¾›è„šæœ¬è¯»å–ï¼ˆé¿å…ä¾èµ–å¤–éƒ¨æ–‡ä»¶ï¼‰
    if 'DEBUG_MODE' in globals() and DEBUG_MODE:
        test_file = Path(OUTPUT_DIR) / "debug_test_subjects.xlsx"
        if not test_file.exists():
            df_test = pd.DataFrame([
                {
                    'æ€§åˆ«': 'å¥³', 'å¹´é¾„': 30, 'æœ€é«˜æ•™è‚²æ°´å¹³': 'å­¦å£«åŠä»¥ä¸Šå­¦ä½',
                    'èŒä¸š': 'ä¸“ä¸šæŠ€æœ¯ç±»', 'è¡Œä¸š': 'ä¸“ä¸šåŠç›¸å…³æœåŠ¡', 'å®¶åº­å¹´æ€»æ”¶å…¥': '$50,000â€“$74,999'
                },
                {
                    'æ€§åˆ«': 'ç”·', 'å¹´é¾„': 45, 'æœ€é«˜æ•™è‚²æ°´å¹³': 'é«˜ä¸­æ¯•ä¸š',
                    'èŒä¸š': 'æœåŠ¡è¡Œä¸š', 'è¡Œä¸š': 'ä¸ªäººæœåŠ¡', 'å®¶åº­å¹´æ€»æ”¶å…¥': '$25,000â€“$49,999'
                }
            ])
            df_test.to_excel(test_file, index=False, engine='openpyxl')
            print(f"âš™ï¸ DEBUG: ç”Ÿæˆæµ‹è¯•å—è¯•è€…æ–‡ä»¶ -> {test_file}")
        # è¦†ç›–å…¨å±€ SUBJECT_BACKGROUND_FILE æŒ‡å‘æµ‹è¯•æ–‡ä»¶
        SUBJECT_BACKGROUND_FILE = str(test_file)

    # Run main process
    main()