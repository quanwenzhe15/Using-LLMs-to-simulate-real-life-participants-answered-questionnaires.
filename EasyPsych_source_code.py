# -*- coding: utf-8 -*-
"""
Questionnaire Simulation System (Adapted for American Participants)
- Reads subject background Excel (Gender/Age/Highest Education Level only)
- Calls Alibaba Cloud Qwen-plus API for simulated responses
- Retains target dimensions: Emotional Abuse, Emotional Neglect, Supervisor Support, Personal Mastery, Perceived Constraints, Job insecurity
- Features: Random question order + No same dimension for 4 consecutive times + API retry + Failure handling + Fatal error stop & save
- Automatically parses scores, handles reverse coding, outputs standardized Excel results
"""
import os
import re
import pandas as pd
from pathlib import Path
import concurrent.futures
import sys
import time
from collections import deque

def resource_path(relative_path):
    """è·å–èµ„æºæ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œå…¼å®¹PyInstalleræ‰“åŒ…åçš„ç¯å¢ƒ"""
    try:
        # PyInstalleråˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹å¹¶è®¾ç½®_MEIPASS
        base_path = sys._MEIPASS
    except Exception:
        # æ­£å¸¸å¼€å‘ç¯å¢ƒ
        base_path = os.path.dirname(os.path.abspath(__file__))
    return os.path.join(base_path, relative_path)

# åŠ¨æ€å¯¼å…¥å¤šè¯­è¨€é…ç½®ï¼Œå…¼å®¹æ‰“åŒ…ç¯å¢ƒ
def import_language_config():
    """åŠ¨æ€å¯¼å…¥å¤šè¯­è¨€é…ç½®"""
    try:
        # å°è¯•ç›´æ¥å¯¼å…¥
        from language_config import get_text, get_column_names, set_language, CURRENT_LANGUAGE
        return get_text, get_column_names, set_language, CURRENT_LANGUAGE
    except ImportError:
        # å¦‚æœç›´æ¥å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä»èµ„æºè·¯å¾„å¯¼å…¥
        import sys
        import importlib.util
        
        language_config_path = resource_path("language_config.py")
        
        # ä½¿ç”¨importlibåŠ¨æ€å¯¼å…¥
        spec = importlib.util.spec_from_file_location("language_config", language_config_path)
        language_config = importlib.util.module_from_spec(spec)
        sys.modules["language_config"] = language_config
        spec.loader.exec_module(language_config)
        
        return language_config.get_text, language_config.get_column_names, language_config.set_language, language_config.CURRENT_LANGUAGE

# å¯¼å…¥å¤šè¯­è¨€é…ç½®å‡½æ•°
get_text, get_column_names, set_language, CURRENT_LANGUAGE = import_language_config()

# APIé”™è¯¯ç›‘æ§å…¨å±€å˜é‡
API_ERROR_HISTORY = deque(maxlen=5)  # è®°å½•æœ€è¿‘5æ¬¡APIè°ƒç”¨çŠ¶æ€
CONSECUTIVE_FAILURES = 0  # è¿ç»­å¤±è´¥æ¬¡æ•°
MAX_CONSECUTIVE_FAILURES = 5  # æœ€å¤§å…è®¸è¿ç»­å¤±è´¥æ¬¡æ•°
MAX_RETRY_ATTEMPTS = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°

# Show welcome and license agreement window
import tkinter as tk
from tkinter import messagebox, ttk

# Create welcome and license agreement window
def show_welcome_and_license():
    root = tk.Tk()
    root.title(get_text("welcome_title"))
    root.geometry("700x600")
    root.resizable(True, True)
    
    # Create main frame
    main_frame = tk.Frame(root, padx=20, pady=20)
    main_frame.pack(fill=tk.BOTH, expand=True)
    
    # Welcome message
    welcome_label = tk.Label(main_frame, text=get_text("welcome_message"), font=('Arial', 14, 'bold'))
    welcome_label.pack(pady=10)
    
    # Create a notebook for different sections
    notebook = ttk.Notebook(main_frame)
    notebook.pack(fill=tk.BOTH, expand=True, pady=10)
    
    # Functionality tab
    func_tab = tk.Frame(notebook)
    notebook.add(func_tab, text="åŠŸèƒ½ä»‹ç»")
    
    func_text = tk.Text(func_tab, wrap=tk.WORD, padx=10, pady=10)
    func_text.pack(fill=tk.BOTH, expand=True)
    func_text.insert(tk.END, "æœ¬ç³»ç»Ÿä¸»è¦åŠŸèƒ½ï¼š\n\n")
    func_text.insert(tk.END, "1. æ”¯æŒå¤šç§é—®å·æ–‡ä»¶æ ¼å¼ï¼šExcel (.xlsx, .xls)ã€CSV (.csv) å’Œ Word (.docx)\n")
    func_text.insert(tk.END, "2. è‡ªåŠ¨è§£æé—®å·ç»“æ„ï¼Œæå–é¢˜ç›®ã€ç»´åº¦ã€è®¡åˆ†æ ‡å‡†ç­‰ä¿¡æ¯\n")
    func_text.insert(tk.END, "3. æ”¯æŒéšæœºé¢˜ç›®é¡ºåºï¼Œå¯é™åˆ¶åŒä¸€ç»´åº¦è¿ç»­å‡ºç°æ•°é‡\n")
    func_text.insert(tk.END, "4. é›†æˆå¤§æ¨¡å‹ APIï¼Œå¤„ç†å¤æ‚é—®å·ç»“æ„\n")
    func_text.insert(tk.END, "5. æ¨¡æ‹Ÿè¢«è¯•å›ç­”ï¼Œç”Ÿæˆæ ‡å‡†åŒ–ç»“æœæ–‡ä»¶\n")
    func_text.insert(tk.END, "6. æ”¯æŒåå‘è®¡åˆ†é¢˜å¤„ç†\n")
    func_text.insert(tk.END, "7. æ”¯æŒè‡ªå®šä¹‰è®¡åˆ†è§„åˆ™ï¼Œå¯æ ¹æ®éœ€è¦ä¿®æ”¹è®¡åˆ†æ ‡å‡†\n")
    func_text.config(state=tk.DISABLED)
    
    # File format tab
    file_tab = tk.Frame(notebook)
    notebook.add(file_tab, text="æ–‡ä»¶æ ¼å¼è¦æ±‚")
    
    file_text = tk.Text(file_tab, wrap=tk.WORD, padx=10, pady=10)
    file_text.pack(fill=tk.BOTH, expand=True)
    file_text.insert(tk.END, "æ–‡ä»¶æ ¼å¼è¦æ±‚ï¼š\n\n")
    file_text.insert(tk.END, "é—®å·æ–‡ä»¶ï¼š\n")
    file_text.insert(tk.END, "- Excel æ–‡ä»¶ (.xlsx, .xls)ï¼šå¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—ï¼šé¢˜ç›®IDã€é¢˜ç›®æ‰€å±ç»´åº¦ã€é¢˜ç›®å†…å®¹ã€è®¡åˆ†æ ‡å‡†\n")
    file_text.insert(tk.END, "- CSV æ–‡ä»¶ (.csv)ï¼šå¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—ï¼šé¢˜ç›®IDã€é¢˜ç›®æ‰€å±ç»´åº¦ã€é¢˜ç›®å†…å®¹ã€è®¡åˆ†æ ‡å‡†\n")
    file_text.insert(tk.END, "- Word æ–‡ä»¶ (.docx)ï¼šæŒ‰ç»´åº¦åˆ†èŠ‚ï¼Œç»´åº¦æ ‡é¢˜ä»¥å†’å·ç»“å°¾\n")
    file_text.insert(tk.END, "- é¢˜ç›®æ ¼å¼è¦æ±‚ï¼šå¿…é¡»åŒ…å«æ¥å›åŒå¼•å·ï¼Œä¾‹å¦‚ï¼š4. \"People in my family felt close to each other.\" (R)\n")
    file_text.insert(tk.END, "- æ”¯æŒçš„é¢˜ç›®æ ¼å¼ï¼š\n")
    file_text.insert(tk.END, "  * æ ‡å‡†æ•°å­—ç¼–å·ï¼š1. \"Question text\" (R)\n")
    file_text.insert(tk.END, "  * å¸¦æ˜Ÿå·ï¼š*1. \"Question text\" (R)\n")
    file_text.insert(tk.END, "  * é¡¹ç›®ç¬¦å·ï¼šâ€¢ \"Question text\" (R)\n")
    file_text.insert(tk.END, "  * å¸¦ç©ºæ ¼ï¼š1 \"Question text\" (R)\n")
    file_text.insert(tk.END, "- è®¡åˆ†è§„åˆ™æ ¼å¼ï¼šCoding: åè¿æ¥çš„ä¸€å¥è¯ï¼Œä»¥å¥å·ç»“å°¾ï¼Œä¾‹å¦‚ï¼šCoding: 1 Never true; 2 Rarely true; 3 Sometimes true; 4 Often true; 5 Very often true. \n")
    file_text.insert(tk.END, "- æ”¯æŒåå‘è®¡åˆ†æ ‡è®°ï¼š(R) æˆ– (åå‘)\n")
    file_text.insert(tk.END, "- æ”¯æŒå¤šç§è®¡åˆ†èŒƒå›´ï¼š1-5ã€1-7ã€1-6ç­‰ï¼ˆè‡ªåŠ¨è¯†åˆ«ï¼‰\n\n")
    file_text.insert(tk.END, "è¢«è¯•èƒŒæ™¯æ–‡ä»¶ï¼š\n")
    file_text.insert(tk.END, "- æ”¯æŒæ ¼å¼ï¼šExcel (.xlsx, .xls) å’Œ CSV (.csv)\n")
    file_text.insert(tk.END, "- å¼ºåˆ¶è¦æ±‚çš„åˆ—ï¼šè¢«è¯•IDã€å¹´é¾„ã€æ€§åˆ«\n")
    file_text.insert(tk.END, "- å…¶ä»–åˆ—ä¼šè¢«è‡ªåŠ¨è§£æå¹¶åŠ å…¥åˆ°æç¤ºä¸­\n")
    file_text.insert(tk.END, "- ç©ºå€¼ä¼šè¢«å¡«å……ä¸º'ä¸é€‚ç”¨'ï¼Œå¹¶ç”Ÿæˆç¼ºå¤±å€¼æŠ¥å‘Š\n")
    file_text.insert(tk.END, "- å¦‚æœæŸåˆ—ç¼ºå¤±å€¼è¶…è¿‡20%ï¼Œä¼šå¼¹çª—å‘ŠçŸ¥å¹¶è®©ç”¨æˆ·é€‰æ‹©æ˜¯å¦ç»§ç»­\n")
    file_text.config(state=tk.DISABLED)
    
    # Usage guide tab
    guide_tab = tk.Frame(notebook)
    notebook.add(guide_tab, text="ä½¿ç”¨æŒ‡å—")
    
    guide_text = tk.Text(guide_tab, wrap=tk.WORD, padx=10, pady=10)
    guide_text.pack(fill=tk.BOTH, expand=True)
    guide_text.insert(tk.END, "ä½¿ç”¨æŒ‡å—ï¼š\n\n")
    guide_text.insert(tk.END, "1. è¿è¡Œè„šæœ¬åï¼Œåœ¨æ¬¢è¿çª—å£ä¸­é˜…è¯»å¹¶åŒæ„åè®®\n")
    guide_text.insert(tk.END, "2. åœ¨è®¾ç½®çª—å£ä¸­é…ç½® API å‚æ•°ï¼ˆå¦‚éœ€è¦ï¼‰\n")
    guide_text.insert(tk.END, "3. é€‰æ‹©æ˜¯å¦å¯ç”¨éšæœºé¢˜ç›®é¡ºåºåŠè¿ç»­ç»´åº¦é™åˆ¶\n")
    guide_text.insert(tk.END, "4. é€‰æ‹©é—®å·æ–‡ä»¶ï¼ˆExcelã€CSV æˆ– Word æ ¼å¼ï¼‰\n")
    guide_text.insert(tk.END, "5. é€‰æ‹©è¢«è¯•èƒŒæ™¯æ–‡ä»¶ï¼ˆExcel æ ¼å¼ï¼‰\n")
    guide_text.insert(tk.END, "6. é€‰æ‹©è¾“å‡ºç»“æœè·¯å¾„\n")
    guide_text.insert(tk.END, "7. ç‚¹å‡»'å¼€å§‹è¿è¡Œ'æŒ‰é’®å¼€å§‹å¤„ç†\n")
    guide_text.config(state=tk.DISABLED)
    
    # License tab
    license_tab = tk.Frame(notebook)
    notebook.add(license_tab, text="è®¸å¯è¯åè®®")
    
    license_text = tk.Text(license_tab, wrap=tk.WORD, padx=10, pady=10)
    license_text.pack(fill=tk.BOTH, expand=True)
    license_text.insert(tk.END, "GNU GENERAL PUBLIC LICENSE\n")
    license_text.insert(tk.END, "Version 3, 29 June 2007\n\n")
    license_text.insert(tk.END, "æœ¬ç¨‹åºæ˜¯è‡ªç”±è½¯ä»¶ï¼šæ‚¨å¯ä»¥æ ¹æ®è‡ªç”±è½¯ä»¶åŸºé‡‘ä¼šå‘å¸ƒçš„ GNU é€šç”¨å…¬å…±è®¸å¯è¯æ¡æ¬¾\n")
    license_text.insert(tk.END, "ï¼ˆæœ¬è®¸å¯è¯çš„ç¬¬ 3 ç‰ˆæˆ–æ‚¨é€‰æ‹©çš„ä»»ä½•æ›´é«˜ç‰ˆæœ¬ï¼‰æ¥é‡æ–°åˆ†å‘å’Œ/æˆ–ä¿®æ”¹å®ƒã€‚\n\n")
    license_text.insert(tk.END, "æœ¬ç¨‹åºçš„å‘å¸ƒæ˜¯å¸Œæœ›å®ƒèƒ½æœ‰ç”¨ï¼Œä½†æ²¡æœ‰ä»»ä½•æ‹…ä¿ï¼›ç”šè‡³æ²¡æœ‰å¯¹é€‚é”€æ€§æˆ–\n")
    license_text.insert(tk.END, "ç‰¹å®šç”¨é€”é€‚ç”¨æ€§çš„é»˜ç¤ºæ‹…ä¿ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… GNU é€šç”¨å…¬å…±è®¸å¯è¯ã€‚\n\n")
    license_text.insert(tk.END, "æ‚¨åº”è¯¥å·²ç»æ”¶åˆ°äº†ä¸€ä»½ GNU é€šç”¨å…¬å…±è®¸å¯è¯çš„å‰¯æœ¬ã€‚å¦‚æœæ²¡æœ‰ï¼Œè¯·å‚è§\n")
    license_text.insert(tk.END, "<https://www.gnu.org/licenses/>.\n")
    license_text.config(state=tk.DISABLED)
    
    # Agreement frame
    agree_frame = tk.Frame(main_frame, pady=10)
    agree_frame.pack(fill=tk.X)
    
    agree_var = tk.BooleanVar(value=False)
    agree_checkbox = tk.Checkbutton(agree_frame, text=get_text("terms_agree"), variable=agree_var, font=('Arial', 10))
    agree_checkbox.pack(pady=5)
    
    # Button frame
    button_frame = tk.Frame(main_frame, pady=10)
    button_frame.pack(fill=tk.X)
    
    def on_continue():
        if agree_var.get():
            root.destroy()
        else:
            messagebox.showerror(get_text("error"), get_text("terms_must_agree"))
    
    def on_cancel():
        root.destroy()
        # Exit the program
        import sys
        sys.exit(0)
    
    continue_button = tk.Button(button_frame, text=get_text("continue_button"), command=on_continue, font=('Arial', 10, 'bold'), width=15)
    continue_button.pack(side=tk.RIGHT, padx=5)
    
    cancel_button = tk.Button(button_frame, text=get_text("exit_button"), command=on_cancel, font=('Arial', 10), width=10)
    cancel_button.pack(side=tk.RIGHT, padx=5)
    
    # Run the window
    root.mainloop()

# Show welcome and license window
show_welcome_and_license()

# Check and install required dependencies with user consent
required_packages = ['tenacity', 'python-docx']
optional_packages = ['pypinyin']  # Optional packages for enhanced functionality
missing_packages = []

# First check for missing packages
for package in required_packages:
    try:
        if package == 'tenacity':
            from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
        elif package == 'python-docx':
            # å…ˆå°è¯•å¯¼å…¥ï¼Œå³ä½¿å¤±è´¥ä¹Ÿä¸ç«‹å³æŠ¥é”™
            from docx import Document
    except ImportError:
        missing_packages.append(package)

# Check for optional packages
optional_missing = []
for package in optional_packages:
    try:
        if package == 'pypinyin':
                from pypinyin import lazy_pinyin  # type: ignore
    except ImportError:
        optional_missing.append(package)

# If there are missing packages, ask user for consent to install
if missing_packages:
    # Initialize tkinter for the message box
    import tkinter as tk
    from tkinter import messagebox
    
    # Create a root window but hide it
    root = tk.Tk()
    root.withdraw()
    
    # Prepare message
    packages_str = ', '.join(missing_packages)
    message = f"ç³»ç»Ÿæ£€æµ‹åˆ°ç¼ºå°‘ä»¥ä¸‹å¿…è¦çš„åº“ï¼š\n{packages_str}\n\næ˜¯å¦åŒæ„è‡ªåŠ¨å®‰è£…è¿™äº›åº“ï¼Ÿ"
    
    # Ask user for consent
    user_consent = messagebox.askyesno("ç¼ºå°‘å¿…è¦åº“", message)
    
    # Destroy the root window
    root.destroy()
    
    if user_consent:
        # Install missing packages
        for package in missing_packages:
            print(f"Installing required package '{package}'...")
            os.system(f"pip install {package}")
        
        # Re-import after installation
        for package in required_packages:
            if package == 'tenacity':
                from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
            elif package == 'python-docx':
                from docx import Document
    else:
        # Userä¸åŒæ„å®‰è£…ï¼Œåœæ­¢è¿è¡Œ
        print("ç”¨æˆ·ä¸åŒæ„å®‰è£…å¿…è¦çš„åº“ï¼Œç¨‹åºé€€å‡º")
        exit(1)

# Check for optional packages
if optional_missing:
    # Initialize tkinter for the message box
    import tkinter as tk
    from tkinter import messagebox
    
    # Create a root window but hide it
    root = tk.Tk()
    root.withdraw()
    
    # Prepare message
    packages_str = ', '.join(optional_missing)
    message = f"ç³»ç»Ÿæ£€æµ‹åˆ°ç¼ºå°‘ä»¥ä¸‹å¯é€‰çš„åº“ï¼ˆç”¨äºå¢å¼ºåŠŸèƒ½ï¼‰ï¼š\n{packages_str}\n\nè¿™äº›åº“ç”¨äºæ‹¼éŸ³è½¬æ¢åŠŸèƒ½ï¼Œç¼ºå°‘å®ƒä»¬ä¸ä¼šå½±å“åŸºæœ¬åŠŸèƒ½ã€‚\n\næ˜¯å¦åŒæ„è‡ªåŠ¨å®‰è£…è¿™äº›åº“ï¼Ÿ"
    
    # Ask user for consent
    user_consent = messagebox.askyesno("ç¼ºå°‘å¯é€‰åº“", message)
    
    # Destroy the root window
    root.destroy()
    
    if user_consent:
        # Install missing packages
        for package in optional_missing:
            print(f"Installing optional package '{package}'...")
            os.system(f"pip install {package}")

# Now import remaining modules
from openai import OpenAI
from datetime import datetime
# tenacity, docx, tkinter are already imported in the welcome window section
from tkinter import filedialog, messagebox

# ---------------- Core Configuration (Adjust as Needed) ----------------
# API Configuration (Alibaba Cloud Qwen)
def load_config():
    """åŠ¨æ€åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = resource_path("config.py")
    
    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ¨¡å—æ¥åŠ è½½é…ç½®
    import importlib.util
    spec = importlib.util.spec_from_file_location("config", config_path)
    config = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(config)
    
    return config

# Import configuration from config.py
config = load_config()
DASHSCOPE_API_KEY = getattr(config, 'DASHSCOPE_API_KEY', '')
BASE_URL = getattr(config, 'BASE_URL', '')
MODEL_NAME = getattr(config, 'MODEL_NAME', '')

# File Path Configuration
SUBJECT_BACKGROUND_FILE = ""  # Subject background Excel path (will be selected in GUI)
OUTPUT_DIR = ""  # Result output directory (will be selected in GUI)

MAX_TOKENS = 512  # Maximum length per response
TEMPERATURE = 0.7  # Response diversity (0.7 = close to real human)
#MAX_CONSECUTIVE_SAME_DIM = 3  # Max 3 consecutive questions from same dimension (no 4+)
API_RETRY_TIMES = 3  # API retry times (3 times by default)
API_RETRY_DELAY = 2  # Initial retry delay (2 seconds, exponential backoff)

# DEBUG: æœ¬åœ°æµ‹è¯•å¼€å…³ï¼ˆTrue=ä½¿ç”¨æ¨¡æ‹Ÿ LLM å“åº”å¹¶è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•å—è¯•è€…æ–‡ä»¶ï¼‰
DEBUG_MODE = False

# Global flag: Fatal API error (arrearage/access denied)
FATAL_API_ERROR = False
FATAL_ERROR_MSG = ""

# Initialize API Client (OpenAI-compatible format)
client = OpenAI(
    api_key=DASHSCOPE_API_KEY,
    base_url=BASE_URL,
)

# ---------------- File Analysis Logic Explanation ----------------
"""
æ–‡ä»¶åˆ†æé€»è¾‘è¯´æ˜ï¼š

1. **æ–‡ä»¶ç±»å‹æ£€æµ‹**ï¼š
   - æ ¹æ®æ–‡ä»¶æ‰©å±•åï¼ˆ.xlsx, .xls, .csv, .docxï¼‰ç¡®å®šæ–‡ä»¶ç±»å‹
   - è°ƒç”¨ç›¸åº”çš„è§£æå‡½æ•°

2. **Excel/CSVæ–‡ä»¶è§£æ**ï¼š
   - è¯»å–æ–‡ä»¶å†…å®¹
   - éªŒè¯å¿…è¦åˆ—ï¼šé¢˜ç›®IDã€é¢˜ç›®æ‰€å±ç»´åº¦ã€é¢˜ç›®å†…å®¹ã€è®¡åˆ†æ ‡å‡†
   - æ£€æŸ¥æ•°æ®å®Œæ•´æ€§ï¼ŒæŒ‡å‡ºå…·ä½“çš„æ— æ•ˆè¡Œ
   - è¯†åˆ«åå‘è®¡åˆ†æ ‡è®°ï¼ˆ(R)æˆ–(åå‘)ï¼‰
   - è‡ªåŠ¨ç¡®å®šè®¡åˆ†èŒƒå›´ï¼ˆåŸºäºè®¡åˆ†æ ‡å‡†ä¸­çš„æ•°å­—ï¼‰
   - ç”Ÿæˆæ ‡å‡†åŒ–çš„é—®é¢˜æ ¼å¼

3. **Wordæ–‡ä»¶è§£æ**ï¼š
   - æå–æ–‡æ¡£ä¸­çš„æ‰€æœ‰æ–‡æœ¬
   - è¯†åˆ«ç»´åº¦æ ‡é¢˜ï¼ˆå¦‚"Emotional Abuse:", "Emotional Neglect:"ç­‰ï¼‰
   - æå–æ¯ä¸ªç»´åº¦ä¸‹çš„é¢˜ç›®å†…å®¹
   - è¯†åˆ«è®¡åˆ†æ ‡å‡†å’Œåå‘è®¡åˆ†æ ‡è®°
   - ç”Ÿæˆæ ‡å‡†åŒ–çš„é—®é¢˜æ ¼å¼

4. **å¤§æ¨¡å‹APIé›†æˆ**ï¼š
   - å½“æ­£åˆ™è¡¨è¾¾å¼è§£æå¤±è´¥æ—¶ï¼Œè‡ªåŠ¨è°ƒç”¨å¤§æ¨¡å‹API
   - ç”Ÿæˆæ ‡å‡†åŒ–çš„JSONæ ¼å¼é—®é¢˜åˆ—è¡¨
   - å¤„ç†å¤æ‚çš„é—®å·ç»“æ„

5. **åŠ¨æ€é¢˜ç›®ä½¿ç”¨**ï¼š
   - å®Œå…¨ä½¿ç”¨è§£æå¾—åˆ°çš„é¢˜ç›®ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç çš„é¢˜ç›®
   - æ”¯æŒä¸åŒç»´åº¦å’Œé¢˜ç›®æ•°é‡çš„é—®å·
   - åŠ¨æ€è®¡ç®—ä¸åŒç»´åº¦çš„é‡è¡¨åˆ†æ•°
"""

# Note: ç¡¬ç¼–ç çš„QUESTIONSå˜é‡å·²ç§»é™¤ï¼Œç°åœ¨å®Œå…¨ä½¿ç”¨è§£æå¾—åˆ°çš„é¢˜ç›®
# The following QUESTIONS variable is only a placeholder and will be replaced by parsed questions
QUESTIONS = []

# ---------------- Tool Functions ----------------
def load_subject_background(file_path, output_dir, min_age=18, max_age=75):
    """Read subject background Excel/CSV, return standardized subject list"""
    print(f"Reading subject background file: {file_path}")
    print(f"Age range filter: {min_age} - {max_age} years")
    try:
        # Determine file type and read accordingly
        file_ext = os.path.splitext(file_path)[1].lower()
        if file_ext == '.csv':
            df = pd.read_csv(file_path, encoding='utf-8-sig')
        else:
            df = pd.read_excel(file_path)
        
        # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºè¯»å–çš„åˆ—å
        print(f"è¯»å–åˆ°çš„åˆ—å: {list(df.columns)}")
        print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
        
        # å¼ºåˆ¶è¦æ±‚çš„åˆ—
        mandatory_cols = ['è¢«è¯•ID', 'å¹´é¾„', 'æ€§åˆ«']
        missing_mandatory = [col for col in mandatory_cols if col not in df.columns]
        if missing_mandatory:
            raise ValueError(f"èƒŒæ™¯æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing_mandatory)}")
        
        # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
        print("å‰3è¡Œæ•°æ®:")
        print(df.head(3))
        
        # 1. ç»Ÿä¸€å¤„ç†ç¼ºå¤±å€¼ï¼šæŠŠæ–‡æœ¬ã€Œç¼ºå¤±å€¼ã€æ›¿æ¢æˆNaNï¼Œæ–¹ä¾¿åç»­å¤„ç†
        df = df.replace("ç¼ºå¤±å€¼", pd.NA)
        
        # 2. è®°å½•ç¼ºå¤±å€¼ä½ç½®
        missing_info = []
        for col in df.columns:
            missing_rows = df[df[col].isna()].index.tolist()
            if missing_rows:
                missing_info.append(f"åˆ— '{col}' åœ¨ç¬¬ {', '.join(map(str, [r+2 for r in missing_rows]))} è¡Œæœ‰ç¼ºå¤±å€¼")
        
        # 3. æ£€æŸ¥åˆ—ç¼ºå¤±æƒ…å†µ
        columns_with_high_missing = []
        total_rows = len(df)
        for col in df.columns:
            missing_count = df[col].isna().sum()
            missing_percentage = (missing_count / total_rows) * 100
            if missing_percentage > 20:
                columns_with_high_missing.append(f"{col} ({missing_percentage:.1f}%)")
        
        # 4. å¦‚æœæœ‰åˆ—ç¼ºå¤±è¶…è¿‡20%ï¼Œå¼¹çª—å‘ŠçŸ¥ç”¨æˆ·
        if columns_with_high_missing:
            # ä½¿ç”¨å…¨å±€å¯¼å…¥çš„tkinteræ¨¡å—
            import tkinter as tk_local
            from tkinter import messagebox
            
            root = tk_local.Tk()
            root.withdraw()
            
            message = f"ä»¥ä¸‹åˆ—çš„ç¼ºå¤±å€¼è¶…è¿‡20%ï¼š\n{', '.join(columns_with_high_missing)}\n\næ˜¯å¦ç»§ç»­è¿è¡Œï¼Ÿ"
            user_choice = messagebox.askyesno("è­¦å‘Šï¼šé«˜ç¼ºå¤±å€¼", message)
            
            root.destroy()
            
            if not user_choice:
                # è¿”å›ç‰¹æ®Šå€¼è¡¨ç¤ºç”¨æˆ·é€‰æ‹©è¿”å›è®¾ç½®ç•Œé¢
                return "RETURN_TO_SETTINGS"
        
        # 5. å¹´é¾„åˆ—æ¸…æ´—ï¼šè½¬æ•°å€¼ç±»å‹ï¼Œæ£€æŸ¥å¹´é¾„èŒƒå›´
        df['å¹´é¾„'] = pd.to_numeric(df['å¹´é¾„'], errors='coerce').astype('Int64')
        
        # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºå¹´é¾„åˆ—çš„åŸºæœ¬ç»Ÿè®¡
        print(f"å¹´é¾„åˆ—ç»Ÿè®¡:")
        print(f"  éç©ºå€¼æ•°é‡: {df['å¹´é¾„'].count()}")
        print(f"  ç©ºå€¼æ•°é‡: {df['å¹´é¾„'].isna().sum()}")
        print(f"  å¹´é¾„èŒƒå›´: {df['å¹´é¾„'].min()} - {df['å¹´é¾„'].max()}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¹´é¾„è¶…å‡ºèŒƒå›´çš„è¢«è¯•
        invalid_age_rows = df[(df['å¹´é¾„'] < min_age) | (df['å¹´é¾„'] > max_age)]
        
        print(f"å¹´é¾„æ— æ•ˆçš„è¢«è¯•æ•°é‡: {len(invalid_age_rows)}")
        
        if not invalid_age_rows.empty:
            # ä½¿ç”¨å…¨å±€å¯¼å…¥çš„tkinteræ¨¡å—
            import tkinter as tk_local
            from tkinter import messagebox
            
            root = tk_local.Tk()
            root.withdraw()
            
            invalid_count = len(invalid_age_rows)
            invalid_ages = invalid_age_rows['å¹´é¾„'].dropna().unique()
            invalid_ages_str = ', '.join(map(str, sorted(invalid_ages)))
            
            message = f"å‘ç° {invalid_count} ä¸ªè¢«è¯•çš„å¹´é¾„ä¸åœ¨è®¾å®šèŒƒå›´({min_age}-{max_age}å²)å†…ã€‚\n"
            message += f"æ— æ•ˆå¹´é¾„: {invalid_ages_str}\n\n"
            message += "æ˜¯å¦ç»§ç»­è¿è¡Œï¼ˆå°†è‡ªåŠ¨è¿‡æ»¤æ‰å¹´é¾„æ— æ•ˆçš„è¢«è¯•ï¼‰ï¼Ÿ"
            
            user_choice = messagebox.askyesno("è­¦å‘Šï¼šå¹´é¾„èŒƒå›´æ£€æŸ¥", message)
            root.destroy()
            
            if not user_choice:
                return []
        
        # è¿‡æ»¤å¹´é¾„åœ¨èŒƒå›´å†…çš„è¢«è¯•
        df = df[(df['å¹´é¾„'] >= min_age) & (df['å¹´é¾„'] <= max_age)]
        
        print(f"å¹´é¾„è¿‡æ»¤åçš„æ•°æ®å½¢çŠ¶: {df.shape}")
        
        # 6. æ–‡æœ¬åˆ—å®‰å…¨å¤„ç†ï¼šå…ˆè½¬å­—ç¬¦ä¸²ï¼Œå†strip
        for col in df.columns:
            if df[col].dtype == 'object' or pd.api.types.is_string_dtype(df[col]):
                # å…ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå¤„ç†å¯èƒ½çš„ç¼–ç é—®é¢˜
                df[col] = df[col].astype(str)
                # å¡«å……ç©ºå€¼
                df[col] = df[col].fillna("ä¸é€‚ç”¨")
                # å»é™¤ä¸¤ç«¯ç©ºæ ¼
                df[col] = df[col].str.strip()
                
        # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºå¤„ç†åçš„æ•°æ®ç±»å‹
        print("å¤„ç†åçš„æ•°æ®ç±»å‹:")
        print(df.dtypes)
        
        # 7. ç”Ÿæˆç¼ºå¤±å€¼æŠ¥å‘Š
        if missing_info:
            # ä½¿ç”¨å…¨å±€å¯¼å…¥çš„osæ¨¡å—
            import os as os_module
            report_path = os_module.path.join(output_dir, "missing_values_report.txt")
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("èƒŒæ™¯æ–‡ä»¶ç¼ºå¤±å€¼æŠ¥å‘Š\n")
                f.write("=" * 50 + "\n")
                f.write(f"æ–‡ä»¶è·¯å¾„: {file_path}\n")
                f.write(f"æ€»è¡Œæ•°: {total_rows}\n")
                f.write(f"æœ‰æ•ˆè¡Œæ•°: {len(df)}\n")
                f.write(f"å¹´é¾„èŒƒå›´: {min_age}-{max_age}å²\n")
                f.write("\nç¼ºå¤±å€¼ä½ç½®:\n")
                for info in missing_info:
                    f.write(f"- {info}\n")
                
                # æ·»åŠ å¹´é¾„æ£€æŸ¥ä¿¡æ¯
                if not invalid_age_rows.empty:
                    f.write(f"\nå¹´é¾„èŒƒå›´æ£€æŸ¥:\n")
                    f.write(f"- è¿‡æ»¤æ‰ {invalid_count} ä¸ªå¹´é¾„æ— æ•ˆçš„è¢«è¯•\n")
                    f.write(f"- æ— æ•ˆå¹´é¾„: {invalid_ages_str}\n")
            
            print(f"ç¼ºå¤±å€¼æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        
        # 8. è¿‡æ»¤æ ¸å¿ƒå­—æ®µå…¨ç©ºçš„è¡Œ
        df = df.dropna(subset=['æ€§åˆ«', 'å¹´é¾„'])
        
        # Convert to subject list
        subjects = []
        for idx, row in df.iterrows():
            subject = {
                "subject_id": int(row['è¢«è¯•ID']) if pd.notna(row['è¢«è¯•ID']) else idx + 1,
                "æ€§åˆ«": row['æ€§åˆ«'],
                "å¹´é¾„": row['å¹´é¾„']
            }
            
            # æ·»åŠ å…¶ä»–åˆ—çš„ä¿¡æ¯
            for col in df.columns:
                if col not in mandatory_cols:
                    subject[col] = row[col]
            
            subjects.append(subject)
        
        print(f"æœ€ç»ˆåŠ è½½çš„æœ‰æ•ˆè¢«è¯•æ•°é‡: {len(subjects)}")
        print(f"æ¯ä¸ªè¢«è¯•çš„å­—æ®µ: {list(subjects[0].keys()) if subjects else 'æ— è¢«è¯•'}")
        
        return subjects
    except Exception as e:
        print(f"Failed to read subject background: {str(e)}")
        import traceback
        traceback.print_exc()  
        return []

def generate_subject_prompt(subject, question, column_strategy="ä¿æŒåŸæ ·"):
    """Generate subject-specific prompt (English, adapted for American context)"""
    # ä¼˜åŒ–ä¸»ç®¡æ”¯æŒå¤‡æ³¨ï¼šæ ¹æ®èŒä¸šæ˜¯å¦ä¸ºç¼ºå¤±/ä¸é€‚ç”¨åˆ¤æ–­
    supervisor_note = ""
    if "ä¸»ç®¡æ”¯æŒ" in question['dimension']:
        if 'èŒä¸š' in subject and subject['èŒä¸š'] in ["ä¸é€‚ç”¨", "æ‹’ç»å›ç­”", "ä¸çŸ¥é“"]:
            supervisor_note = " (Note: If you don't have a supervisor or job, answer based on hypothetical work experience or common sense)"
        elif 'èŒä¸š' in subject and 'è¡Œä¸š' in subject:
            supervisor_note = f" (Note: Answer combined with your occupation as {subject['èŒä¸š']} in {subject['è¡Œä¸š']} industry)"
    
    # Build background information
    background_lines = [
        f"- Gender: {subject['æ€§åˆ«']}",
        f"- Age: {subject['å¹´é¾„']} years old"
    ]
    
    # è‡ªåŠ¨ä¸ºæ‰€æœ‰other fieldsåˆ›å»ºå˜é‡å¹¶æ·»åŠ åˆ°promptä¸­
    other_fields = []
    for key, value in subject.items():
        if key not in ['subject_id', 'æ€§åˆ«', 'å¹´é¾„']:
            # æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„ç­–ç•¥å¤„ç†å­—æ®µå
            english_key = process_column_name(key, column_strategy)
            
            # è·³è¿‡ç©ºå€¼æˆ–æ— æ•ˆå€¼
            if value not in [None, "", "ä¸é€‚ç”¨", "æ‹’ç»å›ç­”", "ä¸çŸ¥é“"]:
                other_fields.append((english_key, value))
    
    # æ·»åŠ å…¶ä»–å­—æ®µåˆ°èƒŒæ™¯ä¿¡æ¯ä¸­
    for english_key, value in other_fields:
        background_lines.append(f"- {english_key}: {value}")
    
    # åŠ¨æ€ç”Ÿæˆå·¥ä½œç›¸å…³æŒ‡å¯¼è¯­
    work_guidance = ""
    if any(field[0].lower() in ['occupation', 'industry', 'work'] for field in other_fields):
        work_guidance = "\n4. For work-related questions, answer based on your occupation and industry if applicable;"
    
    # English prompt template with dynamic fields
    prompt = f"""You are a real American citizen with the following personal background:
{chr(10).join(background_lines)}
Fully embody this role, combine American cultural background, life experiences, and true feelings to answer the following questionnaire in the first person{supervisor_note}. Response requirements:
1. Strictly select a score based on the given coding standard (only enter a number between {question['score_range'][0]}-{question['score_range'][1]});
2. Add 1-2 sentences to explain the reason after the score. The reason should match your background and American social culture, avoiding emptiness;
3. Answer naturally and colloquially, like an ordinary American chattingâ€”no formal writing or AI tone;{work_guidance}
5. Do not reveal you are a simulated role, and never say phrases like "as an AI" or "according to the setting";
6. Only answer based on the current task, do not reference any previous responses.
Question: {question['stem']}
Coding Standard: {question['coding']}
Please answer directly without additional formatting."""
    
    # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºç”Ÿæˆçš„promptç»“æ„
    print(f"Generated prompt for subject {subject.get('subject_id', 'unknown')} with {len(other_fields)} additional fields (strategy: {column_strategy})")
    
    return prompt

def process_column_name(column_name, strategy="ä¿æŒåŸæ ·"):
    """Process column name based on selected strategy"""    # æ ‡å‡†åŒ–åˆ—åï¼šç§»é™¤å¤šä½™çš„ç©ºæ ¼
    normalized_column_name = ''.join(column_name.split())
    
    # å¸¸è§å­—æ®µçš„è‹±æ–‡æ˜ å°„
    field_mappings = {
        'æœ€é«˜æ•™è‚²æ°´å¹³': 'Highest Education Level',
        'èŒä¸š': 'Occupation', 
        'è¡Œä¸š': 'Industry',
        'å®¶åº­å¹´æ€»æ”¶å…¥': 'Annual Household Income',
        'æ•™è‚²æ°´å¹³': 'Education Level',
        'ä¸»ç®¡æ”¯æŒ': 'Supervisor Support',
        'å·¥ä½œå¹´é™': 'Years of Work Experience',
        'å©šå§»çŠ¶å†µ': 'Marital Status',
        'å±…ä½åœ°': 'Residence',
        'æ°‘æ—': 'Ethnicity',
        'å®—æ•™ä¿¡ä»°': 'Religious Belief',
        'å¥åº·çŠ¶å†µ': 'Health Status'
    }
    
    # å¦‚æœå­—æ®µåœ¨æ˜ å°„è¡¨ä¸­ï¼Œä½¿ç”¨æ˜ å°„çš„è‹±æ–‡å
    if column_name in field_mappings:
        return field_mappings[column_name]
    if normalized_column_name in field_mappings:
        return field_mappings[normalized_column_name]
    
    # æ ¹æ®ç­–ç•¥å¤„ç†ä¸åœ¨æ˜ å°„è¡¨ä¸­çš„å­—æ®µ
    if strategy == "ä¿æŒåŸæ ·":
        return column_name  # ä¿æŒä¸­æ–‡å­—æ®µååŸæ ·
    
    elif strategy == "è‡ªåŠ¨ç¿»è¯‘":
        # ç®€å•çš„ä¸­æ–‡åˆ†è¯å’Œç¿»è¯‘å°è¯•
        simple_translations = {
            'å…´è¶£': 'Interest', 'çˆ±å¥½': 'Hobby', 'æ»¡æ„': 'Satisfaction',
            'å‹åŠ›': 'Stress', 'ç”Ÿæ´»': 'Life', 'å·¥ä½œ': 'Work',
            'è´¨é‡': 'Quality', 'æ°´å¹³': 'Level', 'ç¨‹åº¦': 'Degree',
            'å…³ç³»': 'Relationship', 'å®¶åº­': 'Family', 'ç¤¾ä¼š': 'Social',
            'ç»æµ': 'Economic', 'å¿ƒç†': 'Psychological', 'èº«ä½“': 'Physical'
        }
        
        # å°†ä¸­æ–‡å­—æ®µåæ‹†åˆ†ä¸ºå•è¯å¹¶å°è¯•ç¿»è¯‘
        import re
        words = re.findall(r'[\u4e00-\u9fff]+', column_name)
        translated_words = []
        for word in words:
            if word in simple_translations:
                translated_words.append(simple_translations[word])
            else:
                translated_words.append(word)
        return ' '.join(translated_words)
    
    elif strategy == "æ‹¼éŸ³è½¬æ¢":
        # ä½¿ç”¨æ‹¼éŸ³ä½œä¸ºè‹±æ–‡æ ‡è¯†
        try:
            from pypinyin import lazy_pinyin  # type: ignore
            return ''.join(lazy_pinyin(column_name))
        except ImportError:
            # å¦‚æœpypinyinä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€å•æ‹¼éŸ³è½¬æ¢
            pinyin_map = {
                'a': 'ÄÃ¡ÇÃ ', 'e': 'Ä“Ã©Ä›Ã¨', 'i': 'Ä«Ã­ÇÃ¬', 'o': 'ÅÃ³Ç’Ã²', 'u': 'Å«ÃºÇ”Ã¹', 'v': 'Ç–Ç˜ÇšÇœ'
            }
            # ç®€å•çš„æ‹¼éŸ³è½¬æ¢ï¼ˆä»…å¤„ç†åŸºæœ¬æ±‰å­—ï¼‰
            result = ''
            for char in column_name:
                if '\u4e00' <= char <= '\u9fff':  # ä¸­æ–‡å­—ç¬¦
                    # ç®€å•çš„æ‹¼éŸ³æ˜ å°„ï¼ˆå®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨pypinyinï¼‰
                    result += char
                else:
                    result += char
            return result
    
    elif strategy == "è‡ªå®šä¹‰æ˜ å°„":
        # åœ¨ç¼–è¾‘æç¤ºæ¨¡æ¿æ—¶æ‰‹åŠ¨æŒ‡å®šï¼Œè¿™é‡Œä¿æŒåŸæ ·
        return column_name
    
    else:
        # é»˜è®¤ç­–ç•¥ï¼šä¿æŒåŸæ ·
        return column_name

def map_text_to_score(text, question):
    """Map text description to score (for responses without explicit numbers)"""
    text_lower = text.lower()
    min_s, max_s = question['score_range']
    coding_type = question['coding']
    
    # 1-5 points (Never true â†’ Very often true)
    if "Never true" in coding_type:
        if any(w in text_lower for w in ["never", "never true", "not at all"]):
            return 1
        elif any(w in text_lower for w in ["rarely", "seldom"]):
            return 2
        elif any(w in text_lower for w in ["sometimes", "occasionally"]):
            return 3
        elif any(w in text_lower for w in ["often", "frequently"]):
            return 4
        elif any(w in text_lower for w in ["very often", "always", "constantly"]):
            return 5
    # 1-5 points (All the time â†’ Never)
    elif "All the time" in coding_type:
        if any(w in text_lower for w in ["all the time", "always"]):
            return 1
        elif any(w in text_lower for w in ["most of the time", "usually"]):
            return 2
        elif any(w in text_lower for w in ["sometimes", "occasionally"]):
            return 3
        elif any(w in text_lower for w in ["rarely", "seldom"]):
            return 4
        elif any(w in text_lower for w in ["never", "not at all"]):
            return 5
    # 1-7 points (Strongly agree â†’ Strongly disagree)
    elif "Strongly agree" in coding_type:
        if any(w in text_lower for w in ["strongly agree", "fully agree", "completely agree"]):
            return 1
        elif any(w in text_lower for w in ["somewhat agree", "partially agree"]):
            return 2
        elif any(w in text_lower for w in ["a little agree", "slightly agree"]):
            return 3
        elif any(w in text_lower for w in ["don't know", "unsure", "no idea"]):
            return 4
        elif any(w in text_lower for w in ["a little disagree", "slightly disagree"]):
            return 5
        elif any(w in text_lower for w in ["somewhat disagree", "partially disagree"]):
            return 6
        elif any(w in text_lower for w in ["strongly disagree", "completely disagree"]):
            return 7
    # 1-5 points (Excellent â†’ Poor)
    elif "Excellent" in coding_type:
        if any(w in text_lower for w in ["excellent", "very good", "definitely"]):
            return 1
        elif any(w in text_lower for w in ["very good", "highly likely"]):
            return 2
        elif any(w in text_lower for w in ["good", "likely"]):
            return 3
        elif any(w in text_lower for w in ["fair", "so-so", "uncertain"]):
            return 4
        elif any(w in text_lower for w in ["poor", "unlikely", "definitely not"]):
            return 5
    
    return None

@retry(
    stop=stop_after_attempt(API_RETRY_TIMES),
    wait=wait_exponential(multiplier=1, min=API_RETRY_DELAY),  # å…³é”®ï¼šmin=åˆå§‹å»¶è¿Ÿï¼Œæ›¿ä»£é”™è¯¯çš„initial/initial_delay
    retry=retry_if_exception_type(Exception),
    reraise=True
)
def call_llm(prompt, max_tokens=None):
    """Call Qwen API with retry mechanism, return raw response"""
    global FATAL_API_ERROR, FATAL_ERROR_MSG
    try:
        # Use provided max_tokens or default to MAX_TOKENS
        tokens_to_use = max_tokens if max_tokens is not None else MAX_TOKENS
        
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "user", "content": prompt}  # è¡¥å…¨ä½ ä»£ç æˆªæ–­çš„messageséƒ¨åˆ†
            ],
            max_tokens=tokens_to_use,
            temperature=TEMPERATURE
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        error_msg = str(e)
        if any(keyword in error_msg for keyword in ["InvalidApiKey", "Arrearage", "AccessDenied"]):
            FATAL_API_ERROR = True
            FATAL_ERROR_MSG = error_msg
        raise

# å¦‚æœå¯ç”¨ DEBUG_MODEï¼Œåˆ™è¦†ç›– call_llm ä¸ºæœ¬åœ°æ¨¡æ‹Ÿå‡½æ•°ï¼ˆä¸è°ƒç”¨å¤–éƒ¨ APIï¼‰
if 'DEBUG_MODE' in globals() and DEBUG_MODE:
    print("âš™ï¸ DEBUG_MODE å¯ç”¨ï¼šAPI è°ƒç”¨å°†è¢«æ¨¡æ‹Ÿï¼ˆæœ¬åœ°æµ‹è¯•ï¼‰")
    _mock_counter = {'c': 0}
    def _mock_call_llm(prompt):
        # åŸºäºè®¡æ•°å¾ªç¯ç”Ÿæˆ 1-5 çš„åˆ†æ•°ï¼Œä»¥ä¿è¯å¤šæ ·æ€§å’Œå¯é¢„æµ‹æ€§
        _mock_counter['c'] += 1
        score = (_mock_counter['c'] % 5) + 1
        reason = f"Mock response #{_mock_counter['c']}: simulated reason matching prompt."
        return f"{score} {reason}"
    # è¦†ç›–çœŸå®çš„ call_llmï¼ˆç”¨äºæµ‹è¯•ï¼‰
    call_llm = _mock_call_llm

def process_single_question(args):
    """Process a single question for a subject (for concurrent execution)"""
    global API_ERROR_HISTORY, CONSECUTIVE_FAILURES, MAX_CONSECUTIVE_FAILURES, MAX_RETRY_ATTEMPTS
    
    subject, question, column_strategy, api_settings = args
    
    try:
        prompt = generate_subject_prompt(subject, question, column_strategy)
        raw_resp = call_llm(prompt, api_settings.get('max_tokens'))
        score, reason = parse_question_response(raw_resp, question)
        
        # APIè°ƒç”¨æˆåŠŸï¼Œè®°å½•æˆåŠŸçŠ¶æ€
        API_ERROR_HISTORY.append(True)
        CONSECUTIVE_FAILURES = 0
        
        # åŠ¨æ€æ„å»ºå“åº”è®°å½•
        response_record = {
            "è¢«è¯•ID": subject['subject_id'],
            "æ€§åˆ«": subject['æ€§åˆ«'],
            "å¹´é¾„": subject['å¹´é¾„'],
            "éšæœºé¢˜ç›®åºå·": question.get('random_index', 0),
            "åŸå§‹é¢˜ç›®ID": question['question_id'],
            "ç»´åº¦": question['dimension'],
            "é¢˜ç›®å†…å®¹ï¼ˆè‹±æ–‡ï¼‰": question['stem'],
            "è®¡åˆ†æ ‡å‡†ï¼ˆè‹±æ–‡ï¼‰": question['coding'],
            "æ˜¯å¦åå‘è®¡åˆ†": question['reverse_coded'],
            "åŸå§‹å“åº”ï¼ˆè‹±æ–‡ï¼‰": raw_resp,
            "æå–åˆ†æ•°": score,
            "æœ€ç»ˆå¾—åˆ†": score,
            "å›ç­”ç†ç”±ï¼ˆè‹±æ–‡ï¼‰": reason,
            "ä½œç­”çŠ¶æ€": "æˆåŠŸ" if score is not None else "å¤±è´¥"
        }
        
        # æ·»åŠ æ‰€æœ‰å…¶ä»–èƒŒæ™¯æ–‡ä»¶å­—æ®µ
        for key, value in subject.items():
            if key not in ['subject_id', 'æ€§åˆ«', 'å¹´é¾„']:
                response_record[key] = value
        
        return response_record, None
        
    except Exception as error_msg:
        # APIè°ƒç”¨å¤±è´¥ï¼Œè®°å½•å¤±è´¥çŠ¶æ€
        API_ERROR_HISTORY.append(False)
        CONSECUTIVE_FAILURES += 1
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°è¿ç»­å¤±è´¥é˜ˆå€¼
        if CONSECUTIVE_FAILURES >= MAX_CONSECUTIVE_FAILURES:
            # æ£€æŸ¥æœ€è¿‘5æ¬¡è°ƒç”¨ä¸­å¤±è´¥æ¬¡æ•°æ˜¯å¦è¶…è¿‡é˜ˆå€¼
            recent_failures = list(API_ERROR_HISTORY)[-5:]
            failure_count = recent_failures.count(False)
            
            if failure_count >= MAX_CONSECUTIVE_FAILURES:
                # è§¦å‘APIé”™è¯¯è­¦æŠ¥
                global FATAL_API_ERROR, FATAL_ERROR_MSG
                FATAL_API_ERROR = True
                FATAL_ERROR_MSG = f"è¿ç»­APIè°ƒç”¨å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼ˆ{failure_count}/5ï¼‰ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIè´¦æˆ·ä½™é¢"
                print(f"ğŸ”´ APIé”™è¯¯è­¦æŠ¥ï¼šè¿ç»­å¤±è´¥{failure_count}æ¬¡ï¼Œç¨‹åºå°†æš‚åœ")
        
        # æ„å»ºå¤±è´¥è®°å½•
        failed_response = {
            "è¢«è¯•ID": subject['subject_id'],
            "æ€§åˆ«": subject['æ€§åˆ«'],
            "å¹´é¾„": subject['å¹´é¾„'],
            "éšæœºé¢˜ç›®åºå·": question.get('random_index', 0),
            "åŸå§‹é¢˜ç›®ID": question['question_id'],
            "ç»´åº¦": question['dimension'],
            "é¢˜ç›®å†…å®¹ï¼ˆè‹±æ–‡ï¼‰": question['stem'],
            "è®¡åˆ†æ ‡å‡†ï¼ˆè‹±æ–‡ï¼‰": question['coding'],
            "æ˜¯å¦åå‘è®¡åˆ†": question['reverse_coded'],
            "åŸå§‹å“åº”ï¼ˆè‹±æ–‡ï¼‰": f"API_CALL_FAILED: {error_msg}",
            "æå–åˆ†æ•°": None,
            "æœ€ç»ˆå¾—åˆ†": None,
            "å›ç­”ç†ç”±ï¼ˆè‹±æ–‡ï¼‰": "API call failed",
            "ä½œç­”çŠ¶æ€": "å¤±è´¥"
        }
        
        # æ·»åŠ æ‰€æœ‰å…¶ä»–èƒŒæ™¯æ–‡ä»¶å­—æ®µ
        for key, value in subject.items():
            if key not in ['subject_id', 'æ€§åˆ«', 'å¹´é¾„']:
                failed_response[key] = value
        
        return failed_response, {
            "è¢«è¯•ID": subject['subject_id'],
            "é¢˜ç›®ID": question['question_id'],
            "é”™è¯¯åŸå› ": str(error_msg)
        }

def calculate_scale_scores(responses):
    scale_scores = {}
    # æŒ‰ç»´åº¦åˆ†ç»„ç»Ÿè®¡åˆ†æ•°
    dimension_groups = {}
    for resp in responses:
        dim = resp['ç»´åº¦']
        if dim not in dimension_groups:
            dimension_groups[dim] = []
        if resp['æœ€ç»ˆå¾—åˆ†'] is not None:  # ä»…ç»Ÿè®¡æœ‰æ•ˆå¾—åˆ†
            dimension_groups[dim].append(resp['æœ€ç»ˆå¾—åˆ†'])
    
    # åŠ¨æ€è®¡ç®—æ¯ä¸ªç»´åº¦çš„åˆ†æ•°
    for dimension, scores in dimension_groups.items():
        if scores:
            total_score = sum(scores)
            avg_score = round(total_score / len(scores), 2)
            scale_scores[f'{dimension}_æ€»åˆ†'] = total_score
            scale_scores[f'{dimension}_å¹³å‡åˆ†'] = avg_score
        else:
            scale_scores[f'{dimension}_æ€»åˆ†'] = None
            scale_scores[f'{dimension}_å¹³å‡åˆ†'] = None
    
    return scale_scores

# ---------------- Parse LLM Response ----------------
def parse_question_response(raw_resp, question):
    """
    Parse the LLM response to extract the score and reason.
    Returns (score, reason).
    """
    # Try to extract the first number in the valid range as the score
    min_s, max_s = question['score_range']
    # Find all numbers in the response
    numbers = re.findall(r'\d+', raw_resp)
    score = None
    for num in numbers:
        n = int(num)
        if min_s <= n <= max_s:
            score = n
            break
    # If not found, try to map text to score
    if score is None:
        score = map_text_to_score(raw_resp, question)
    # Apply reverse coding if needed
    if score is not None and question.get('reverse_coded', False):
        score = max_s + min_s - score
    # Extract reason: remove the score part from the response
    reason = raw_resp
    if score is not None:
        # Remove the score (number) from the start if present
        reason = re.sub(r'^\s*' + str(score) + r'[\s\.\,\:\-]*', '', raw_resp, count=1).strip()
    return score, reason

def get_random_questions(original_questions):
    """Generate random question order with constraint: no same dimension for consecutive times"""
    while True:
        # Create a copy to avoid modifying original list
        random_questions = original_questions.copy()
        import random
        random.shuffle(random_questions)
        
        # Check if constraint is satisfied
        valid = True
        for i in range(len(random_questions) - MAX_CONSECUTIVE_SAME_DIM):
            # Get current dimension and next dimensions
            current_dim = random_questions[i]['dimension']
            consecutive_dims = [random_questions[j]['dimension'] for j in range(i, i + MAX_CONSECUTIVE_SAME_DIM + 1)]
            
            # If all are same dimension, invalid
            if all(dim == current_dim for dim in consecutive_dims):
                valid = False
                break
        
        if valid:
            return random_questions

def save_current_results(all_results, failed_records, out_dir, output_format="xlsx", is_final=False, output_filename="EasyPsych_Results"):
    """Save current results immediately (even if process is stopped)"""
    if all_results:
        df_out = pd.DataFrame(all_results)
        
        # æŒ‰ç…§è¢«è¯•IDå’Œéšæœºé¢˜ç›®åºå·æ’åºï¼Œç¡®ä¿ç»“æœé¡ºåºæ­£ç¡®
        if 'è¢«è¯•ID' in df_out.columns and 'éšæœºé¢˜ç›®åºå·' in df_out.columns:
            df_out = df_out.sort_values(by=['è¢«è¯•ID', 'éšæœºé¢˜ç›®åºå·'])
        
        # è·å–æ‰€æœ‰åˆ—
        all_columns = list(df_out.columns)
        
        # åˆ†ç¦»èƒŒæ™¯æ–‡ä»¶åˆ—å’Œç³»ç»Ÿç”Ÿæˆåˆ—
        background_columns = []
        system_columns = []
        
        # ç³»ç»Ÿç”Ÿæˆçš„åˆ—ï¼ˆéšæœºé¢˜ç›®åºå·ä¹‹åçš„æ‰€æœ‰åˆ—ï¼‰
        system_generated_columns = [
            "éšæœºé¢˜ç›®åºå·", "åŸå§‹é¢˜ç›®ID", "ç»´åº¦", "é¢˜ç›®å†…å®¹ï¼ˆè‹±æ–‡ï¼‰", "è®¡åˆ†æ ‡å‡†ï¼ˆè‹±æ–‡ï¼‰", "æ˜¯å¦åå‘è®¡åˆ†",
            "åŸå§‹å“åº”ï¼ˆè‹±æ–‡ï¼‰", "æå–åˆ†æ•°", "æœ€ç»ˆå¾—åˆ†", "å›ç­”ç†ç”±ï¼ˆè‹±æ–‡ï¼‰", "ä½œç­”çŠ¶æ€"
        ]
        
        # åŠ¨æ€ç”Ÿæˆçš„é‡è¡¨åˆ†æ•°åˆ—
        score_columns = [col for col in df_out.columns if "_æ€»åˆ†" in col or "_å¹³å‡åˆ†" in col]
        
        # å°†æ‰€æœ‰åˆ—åˆ†ç±»
        for col in all_columns:
            if col in system_generated_columns or col in score_columns:
                system_columns.append(col)
            else:
                background_columns.append(col)
        
        # ç¡®ä¿éšæœºé¢˜ç›®åºå·æ˜¯ç³»ç»Ÿåˆ—çš„ç¬¬ä¸€ä¸ª
        if "éšæœºé¢˜ç›®åºå·" in system_columns:
            system_columns.remove("éšæœºé¢˜ç›®åºå·")
            system_columns.insert(0, "éšæœºé¢˜ç›®åºå·")
        
        # ç»„åˆåˆ—é¡ºåºï¼šèƒŒæ™¯æ–‡ä»¶åˆ— + ç³»ç»Ÿç”Ÿæˆåˆ—
        column_order = background_columns + system_columns
        
        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
        for col in column_order:
            if col not in df_out.columns:
                df_out[col] = None
        df_out = df_out[column_order]
        
        # Generate filename
        if is_final:
            # æ­£å¸¸å®Œæˆæ—¶ä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰æ–‡ä»¶åï¼ˆé»˜è®¤EasyPsych_Resultsï¼‰
            if output_format == "csv":
                output_file = out_dir / f"{output_filename}.csv"
                df_out.to_csv(output_file, index=False, encoding='utf-8-sig')
            else:
                output_file = out_dir / f"{output_filename}.xlsx"
                df_out.to_excel(output_file, index=False, engine='openpyxl')
        else:
            # ä¸­æ–­æ—¶ä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            if output_format == "csv":
                output_file = out_dir / f"Interrupted_Results_{timestamp}.csv"
                df_out.to_csv(output_file, index=False, encoding='utf-8-sig')
            else:
                output_file = out_dir / f"Interrupted_Results_{timestamp}.xlsx"
                df_out.to_excel(output_file, index=False, engine='openpyxl')
        
        print(f"\n Current results saved to: {output_file}")
        
        # Save failed records if any
        if failed_records:
            df_failed = pd.DataFrame(failed_records)
            if output_format == "csv":
                failed_file = out_dir / f"Interrupted_Failed_Records_{timestamp}.csv"
                df_failed.to_csv(failed_file, index=False, encoding='utf-8-sig')
            else:
                failed_file = out_dir / f"Interrupted_Failed_Records_{timestamp}.xlsx"
                df_failed.to_excel(failed_file, index=False, engine='openpyxl')
            print(f" Failed records saved to: {failed_file}")
        
        # Save fatal error info if exists
        if FATAL_API_ERROR:
            error_info = pd.DataFrame([{
                "ç»ˆæ­¢åŸå› ": "APIè‡´å‘½é”™è¯¯",
                "é”™è¯¯è¯¦æƒ…": FATAL_ERROR_MSG,
                "ç»ˆæ­¢æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "å·²å¤„ç†è¢«è¯•æ•°": len(set([r['è¢«è¯•ID'] for r in all_results])),
                "å·²å¤„ç†é¢˜ç›®æ•°": len(all_results)
            }])
            if output_format == "csv":
                error_file = out_dir / f"Fatal_Error_Info_{timestamp}.csv"
                error_info.to_csv(error_file, index=False, encoding='utf-8-sig')
            else:
                error_file = out_dir / f"Fatal_Error_Info_{timestamp}.xlsx"
                error_info.to_excel(error_file, index=False, engine='openpyxl')
            print(f"âœ… Fatal error info saved to: {error_file}")
    else:
        print("\nâš ï¸ No results to save (all_results is empty)")

# ---------------- Integrated GUI Settings ----------------
def show_settings_gui():
    """Show integrated settings GUI with API settings, file selection, and options"""
    root = tk.Tk()
    root.title(get_text("welcome_title"))
    root.geometry("600x700")
    root.resizable(True, True)
    
    # Create main frame
    main_frame = tk.Frame(root, padx=20, pady=20)
    main_frame.pack(fill=tk.BOTH, expand=True)
    
    # Create notebook (tabbed interface)
    notebook = ttk.Notebook(main_frame)
    notebook.pack(fill=tk.BOTH, expand=True)
    
    # ---------------- API Settings Tab ----------------
    api_tab = tk.Frame(notebook)
    notebook.add(api_tab, text=get_text("api_settings"))
    
    # Language Selection
    tk.Label(api_tab, text=get_text("language_settings"), font=('Arial', 10, 'bold')).grid(row=0, column=0, sticky=tk.W, pady=5, padx=10)
    language_var = tk.StringVar(value=CURRENT_LANGUAGE)
    language_frame = tk.Frame(api_tab)
    language_frame.grid(row=0, column=1, pady=5, padx=10, sticky=tk.W)
    
    def update_language():
        """æ›´æ–°ç•Œé¢è¯­è¨€"""
        set_language(language_var.get())
        # æ›´æ–°çª—å£æ ‡é¢˜
        root.title(get_text("welcome_title"))
        # æ›´æ–°æ ‡ç­¾é¡µæ ‡é¢˜
        notebook.tab(0, text=get_text("api_settings"))
        notebook.tab(1, text=get_text("questionnaire_settings"))
        notebook.tab(2, text=get_text("file_selection"))
        
    tk.Radiobutton(language_frame, text=get_text("chinese"), variable=language_var, value="zh", command=update_language).pack(side=tk.LEFT, padx=10)
    tk.Radiobutton(language_frame, text=get_text("english"), variable=language_var, value="en", command=update_language).pack(side=tk.LEFT, padx=10)
    
    # API Key
    tk.Label(api_tab, text=get_text("api_key"), font=('Arial', 10, 'bold')).grid(row=1, column=0, sticky=tk.W, pady=5, padx=10)
    api_key_var = tk.StringVar(value=DASHSCOPE_API_KEY)
    api_key_entry = tk.Entry(api_tab, textvariable=api_key_var, width=50)
    api_key_entry.grid(row=1, column=1, pady=5, padx=10)
    
    # Base URL
    tk.Label(api_tab, text=get_text("base_url"), font=('Arial', 10, 'bold')).grid(row=2, column=0, sticky=tk.W, pady=5, padx=10)
    base_url_var = tk.StringVar(value=BASE_URL)
    base_url_entry = tk.Entry(api_tab, textvariable=base_url_var, width=50)
    base_url_entry.grid(row=2, column=1, pady=5, padx=10)
    
    # Model Name
    tk.Label(api_tab, text=get_text("model_name"), font=('Arial', 10, 'bold')).grid(row=3, column=0, sticky=tk.W, pady=5, padx=10)
    model_name_var = tk.StringVar(value=MODEL_NAME)
    model_name_entry = tk.Entry(api_tab, textvariable=model_name_var, width=50)
    model_name_entry.grid(row=3, column=1, pady=5, padx=10)
    
    # ---------------- Questionnaire Settings Tab ----------------
    q_settings_tab = tk.Frame(notebook)
    notebook.add(q_settings_tab, text=get_text("questionnaire_settings"))
    
    # Random Question Order
    random_order_var = tk.BooleanVar(value=False)
    tk.Checkbutton(q_settings_tab, text=get_text("random_question_order"), variable=random_order_var, font=('Arial', 10)).grid(row=0, column=0, columnspan=2, sticky=tk.W, pady=5, padx=10)
    
    # Max Consecutive Same Dimension
    tk.Label(q_settings_tab, text=get_text("max_consecutive_same_dim"), font=('Arial', 10, 'bold')).grid(row=1, column=0, sticky=tk.W, pady=5, padx=10)
    max_consecutive_var = tk.IntVar(value=3)
    max_consecutive_spin = tk.Spinbox(q_settings_tab, from_=1, to=10, textvariable=max_consecutive_var, width=10)
    max_consecutive_spin.grid(row=1, column=1, sticky=tk.W, pady=5, padx=10)
    
    # Token limit for API analysis
    tk.Label(q_settings_tab, text=get_text("api_token_limit"), font=('Arial', 10, 'bold')).grid(row=2, column=0, sticky=tk.W, pady=5, padx=10)
    token_limit_var = tk.IntVar(value=4000)
    token_frame = tk.Frame(q_settings_tab)
    token_frame.grid(row=2, column=1, pady=5, padx=10, sticky=tk.W)
    token_scale = tk.Scale(token_frame, from_=1000, to=8000, orient=tk.HORIZONTAL, variable=token_limit_var, 
             length=200, resolution=500)
    token_scale.pack(side=tk.LEFT)
    
    # Update token label when scale changes
    def update_token_label(*args):
        token_label.config(text=f"{token_limit_var.get()} {get_text('tokens')}")
    
    token_limit_var.trace("w", update_token_label)
    token_label = tk.Label(token_frame, text=f"{token_limit_var.get()} {get_text('tokens')}")
    token_label.pack(side=tk.LEFT, padx=10)
    
    # MAX_TOKENS setting for individual responses
    tk.Label(q_settings_tab, text=get_text("max_tokens_per_response"), font=('Arial', 10, 'bold')).grid(row=3, column=0, sticky=tk.W, pady=5, padx=10)
    max_tokens_var = tk.IntVar(value=512)
    max_tokens_frame = tk.Frame(q_settings_tab)
    max_tokens_frame.grid(row=3, column=1, pady=5, padx=10, sticky=tk.W)
    tk.Scale(max_tokens_frame, from_=100, to=2000, orient=tk.HORIZONTAL, variable=max_tokens_var, 
             length=200, resolution=50).pack(side=tk.LEFT)
    
    def update_max_tokens_label(*args):
        max_tokens_label.config(text=f"{max_tokens_var.get()} {get_text('tokens')}")
    
    max_tokens_var.trace("w", update_max_tokens_label)
    max_tokens_label = tk.Label(max_tokens_frame, text=f"{max_tokens_var.get()} {get_text('tokens')}")
    max_tokens_label.pack(side=tk.LEFT, padx=10)
    
    # Age range settings
    tk.Label(q_settings_tab, text=get_text("subject_age_range"), font=('Arial', 10, 'bold')).grid(row=4, column=0, sticky=tk.W, pady=5, padx=10)
    age_frame = tk.Frame(q_settings_tab)
    age_frame.grid(row=4, column=1, pady=5, padx=10, sticky=tk.W)
    
    tk.Label(age_frame, text=get_text("min_age")).pack(side=tk.LEFT)
    min_age_var = tk.IntVar(value=18)
    min_age_spin = tk.Spinbox(age_frame, from_=0, to=100, textvariable=min_age_var, width=5)
    min_age_spin.pack(side=tk.LEFT, padx=5)
    
    tk.Label(age_frame, text=get_text("max_age")).pack(side=tk.LEFT, padx=(10, 0))
    max_age_var = tk.IntVar(value=75)
    max_age_spin = tk.Spinbox(age_frame, from_=0, to=100, textvariable=max_age_var, width=5)
    max_age_spin.pack(side=tk.LEFT, padx=5)
    
    # Validate age range
    def validate_age_range():
        min_age = min_age_var.get()
        max_age = max_age_var.get()
        if min_age >= max_age:
            messagebox.showerror("é”™è¯¯", "æœ€å°å¹´é¾„å¿…é¡»å°äºæœ€å¤§å¹´é¾„")
            min_age_var.set(18)
            max_age_var.set(75)
        elif min_age < 0 or max_age > 100:
            messagebox.showerror("é”™è¯¯", "å¹´é¾„èŒƒå›´å¿…é¡»åœ¨0-100å²ä¹‹é—´")
            min_age_var.set(18)
            max_age_var.set(75)
    
    min_age_var.trace("w", lambda *args: validate_age_range())
    max_age_var.trace("w", lambda *args: validate_age_range())
    
    # Custom scoring rules
    tk.Label(q_settings_tab, text=get_text("scoring_rules"), font=('Arial', 10, 'bold')).grid(row=5, column=0, sticky=tk.W, pady=5, padx=10)
    
    def edit_scoring_rules():
        # Create scoring rules edit window
        scoring_window = tk.Toplevel(root)
        scoring_window.title(get_text("edit_scoring_rules"))
        scoring_window.geometry("800x600")
        scoring_window.resizable(True, True)
        
        # Create main frame
        scoring_frame = tk.Frame(scoring_window, padx=20, pady=20)
        scoring_frame.pack(fill=tk.BOTH, expand=True)
        
        # Scoring rules text
        scoring_label = tk.Label(scoring_frame, text=get_text("scoring_rules_settings"), font=('Arial', 10, 'bold'))
        scoring_label.pack(pady=10)
        
        # Text widget for scoring rules
        scoring_text = tk.Text(scoring_frame, wrap=tk.WORD, font=('Arial', 10))
        scoring_text.pack(fill=tk.BOTH, expand=True, pady=10)
        
        # Insert default scoring rules with examples
        default_rules = "# è®¡åˆ†è§„åˆ™è®¾ç½®\n\n"
        default_rules += "## 1. è®¡åˆ†èŒƒå›´è¯†åˆ«è§„åˆ™\n"
        default_rules += "- è‡ªåŠ¨è¯†åˆ«è®¡åˆ†èŒƒå›´ï¼šæ ¹æ®è®¡åˆ†æ ‡å‡†ä¸­çš„æ•°å­—ç¡®å®š\n"
        default_rules += "  ä¾‹å¦‚ï¼šåŒ…å« '7' åˆ™ä¸º 1-7 ç‚¹è®¡åˆ†ï¼ŒåŒ…å« '6' åˆ™ä¸º 1-6 ç‚¹è®¡åˆ†\n"
        default_rules += "  é»˜è®¤ä¸º 1-5 ç‚¹è®¡åˆ†\n\n"
        
        default_rules += "## 2. åå‘è®¡åˆ†è§„åˆ™\n"
        default_rules += "- è‡ªåŠ¨è¯†åˆ«åå‘è®¡åˆ†æ ‡è®°ï¼š(R) æˆ– (åå‘)\n"
        default_rules += "- åå‘è®¡åˆ†è®¡ç®—ï¼š(æœ€å°å€¼ + æœ€å¤§å€¼) - åŸå§‹åˆ†æ•°\n"
        default_rules += "  ä¾‹å¦‚ï¼š5ç‚¹è®¡åˆ†ä¸­ï¼ŒåŸå§‹åˆ†æ•°ä¸º 1ï¼Œåˆ™åå‘è®¡åˆ†ä¸º 5\n"
        default_rules += "  ä¾‹å¦‚ï¼š7ç‚¹è®¡åˆ†ä¸­ï¼ŒåŸå§‹åˆ†æ•°ä¸º 2ï¼Œåˆ™åå‘è®¡åˆ†ä¸º 6\n\n"
        
        default_rules += "## 3. ç»´åº¦åˆ†æ•°è®¡ç®—è§„åˆ™\n"
        default_rules += "- ç»´åº¦åˆ†æ•° = è¯¥ç»´åº¦ä¸‹æ‰€æœ‰é¢˜ç›®åˆ†æ•°çš„æ€»å’Œ\n"
        default_rules += "- æ”¯æŒç¼ºå¤±å€¼å¤„ç†ï¼šä»…ä¸€ä¸ªç¼ºå¤±å€¼æ—¶ä½¿ç”¨å‡å€¼æ›¿æ¢\n"
        default_rules += "- æ— ç¼ºå¤±å€¼æ—¶ç›´æ¥æ±‚å’Œ\n\n"
        
        default_rules += "## 4. è‡ªå®šä¹‰è§„åˆ™ç¤ºä¾‹\n"
        default_rules += "# ç¤ºä¾‹1ï¼šä¿®æ”¹è®¡åˆ†èŒƒå›´è¯†åˆ«\n"
        default_rules += "# score_range = (1, 5)  # å¼ºåˆ¶ä½¿ç”¨5ç‚¹è®¡åˆ†\n\n"
        
        default_rules += "# ç¤ºä¾‹2ï¼šä¿®æ”¹åå‘è®¡åˆ†è®¡ç®—\n"
        default_rules += "# reverse_score = max_score - (original_score - min_score)\n\n"
        
        default_rules += "# ç¤ºä¾‹3ï¼šä¿®æ”¹ç»´åº¦åˆ†æ•°è®¡ç®—ä¸ºå¹³å‡å€¼\n"
        default_rules += "# dimension_score = sum(scores) / len(scores)\n\n"
        
        scoring_text.insert(tk.END, default_rules)
        
        # Button frame
        button_frame = tk.Frame(scoring_frame, pady=10)
        button_frame.pack(fill=tk.X)
        
        def save_scoring_rules():
            # Get the edited scoring rules
            edited_rules = scoring_text.get(1.0, tk.END).strip()
            # Here you could save the rules to a file or update a global variable
            print("Scoring rules updated:")
            print(edited_rules)
            # Close the window
            scoring_window.destroy()
        
        save_button = tk.Button(button_frame, text=get_text("save"), command=save_scoring_rules, font=('Arial', 10, 'bold'), width=15)
        save_button.pack(side=tk.RIGHT, padx=5)
        
        cancel_button = tk.Button(button_frame, text=get_text("cancel"), command=scoring_window.destroy, font=('Arial', 10), width=10)
        cancel_button.pack(side=tk.RIGHT, padx=5)
    
    edit_scoring_button = tk.Button(q_settings_tab, text=get_text("edit_scoring_rules"), command=edit_scoring_rules, font=('Arial', 10))
    edit_scoring_button.grid(row=5, column=1, sticky=tk.W, pady=5, padx=10)
    
    # New column name handling strategy
    tk.Label(q_settings_tab, text=get_text("new_column_strategy"), font=('Arial', 10, 'bold')).grid(row=6, column=0, sticky=tk.W, pady=5, padx=10)
    column_strategy_var = tk.StringVar(value="ä¿æŒåŸæ ·")
    strategy_frame = tk.Frame(q_settings_tab)
    strategy_frame.grid(row=6, column=1, pady=5, padx=10, sticky=tk.W)
    
    # Strategy options with descriptions
    strategies = [
        ("ä¿æŒåŸæ ·", "ä¿æŒä¸­æ–‡å­—æ®µååŸæ ·ï¼ˆæ¨èï¼ŒAIèƒ½ç†è§£ï¼‰"),
        ("è‡ªåŠ¨ç¿»è¯‘", "å°è¯•è‡ªåŠ¨ç¿»è¯‘ä¸ºè‹±æ–‡"),
        ("æ‹¼éŸ³è½¬æ¢", "ä½¿ç”¨æ‹¼éŸ³ä½œä¸ºè‹±æ–‡æ ‡è¯†"),
        ("è‡ªå®šä¹‰æ˜ å°„", "åœ¨ç¼–è¾‘æç¤ºæ¨¡æ¿æ—¶æ‰‹åŠ¨æŒ‡å®šè‹±æ–‡å")
    ]
    
    for i, (strategy, description) in enumerate(strategies):
        rb = tk.Radiobutton(strategy_frame, text=strategy, variable=column_strategy_var, value=strategy)
        rb.grid(row=i, column=0, sticky=tk.W)
        desc_label = tk.Label(strategy_frame, text=description, font=('Arial', 8), fg='gray')
        desc_label.grid(row=i, column=1, sticky=tk.W, padx=(5, 0))
    
    # ---------------- File Selection Tab ----------------
    file_tab = tk.Frame(notebook)
    notebook.add(file_tab, text=get_text("file_selection"))
    
    # Questionnaire File
    tk.Label(file_tab, text=get_text("questionnaire_file"), font=('Arial', 10, 'bold')).grid(row=0, column=0, sticky=tk.W, pady=5, padx=10)
    questionnaire_file_var = tk.StringVar()
    questionnaire_entry = tk.Entry(file_tab, textvariable=questionnaire_file_var, width=40)
    questionnaire_entry.grid(row=0, column=1, pady=5, padx=10)
    tk.Button(file_tab, text=get_text("browse"), command=lambda: questionnaire_file_var.set(filedialog.askopenfilename(
        title=get_text("select_questionnaire_file"),
        filetypes=[("Excelæ–‡ä»¶", "*.xlsx;*.xls"), ("CSVæ–‡ä»¶", "*.csv"), ("Wordæ–‡ä»¶", "*.docx"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
    ))).grid(row=0, column=2, pady=5, padx=10)
    
    # Subject Background File
    tk.Label(file_tab, text=get_text("subject_file"), font=('Arial', 10, 'bold')).grid(row=1, column=0, sticky=tk.W, pady=5, padx=10)
    subject_file_var = tk.StringVar()
    subject_entry = tk.Entry(file_tab, textvariable=subject_file_var, width=40)
    subject_entry.grid(row=1, column=1, pady=5, padx=10)
    tk.Button(file_tab, text=get_text("browse"), command=lambda: subject_file_var.set(filedialog.askopenfilename(
        title=get_text("select_subject_file"),
        filetypes=[("Excelæ–‡ä»¶", "*.xlsx;*.xls"), ("CSVæ–‡ä»¶", "*.csv"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
    ))).grid(row=1, column=2, pady=5, padx=10)
    
    # Output Directory
    tk.Label(file_tab, text=get_text("output_dir"), font=('Arial', 10, 'bold')).grid(row=2, column=0, sticky=tk.W, pady=5, padx=10)
    output_dir_var = tk.StringVar(value=OUTPUT_DIR)
    output_entry = tk.Entry(file_tab, textvariable=output_dir_var, width=40)
    output_entry.grid(row=2, column=1, pady=5, padx=10)
    tk.Button(file_tab, text=get_text("browse"), command=lambda: output_dir_var.set(filedialog.askdirectory(
        title=get_text("select_output_dir")
    ))).grid(row=2, column=2, pady=5, padx=10)
    
    # Output Format
    tk.Label(file_tab, text=get_text("output_format"), font=('Arial', 10, 'bold')).grid(row=3, column=0, sticky=tk.W, pady=5, padx=10)
    output_format_var = tk.StringVar(value="xlsx")
    format_frame = tk.Frame(file_tab)
    format_frame.grid(row=3, column=1, pady=5, padx=10, sticky=tk.W)
    tk.Radiobutton(format_frame, text="Excel (.xlsx)", variable=output_format_var, value="xlsx").pack(side=tk.LEFT, padx=10)
    tk.Radiobutton(format_frame, text="CSV (.csv)", variable=output_format_var, value="csv").pack(side=tk.LEFT, padx=10)
    
    # Output Filename
    tk.Label(file_tab, text=get_text("output_filename"), font=('Arial', 10, 'bold')).grid(row=4, column=0, sticky=tk.W, pady=5, padx=10)
    output_filename_var = tk.StringVar(value="EasyPsych_Results")
    filename_frame = tk.Frame(file_tab)
    filename_frame.grid(row=4, column=1, pady=5, padx=10, sticky=tk.W)
    filename_entry = tk.Entry(filename_frame, textvariable=output_filename_var, width=30)
    filename_entry.pack(side=tk.LEFT)
    tk.Label(filename_frame, text=get_text("no_extension"), fg='gray', font=('Arial', 9)).pack(side=tk.LEFT, padx=5)
    
    # ---------------- Prompt Edit Button ----------------
    def edit_prompt():
        # Create prompt edit window
        prompt_window = tk.Toplevel(root)
        prompt_window.title(get_text("edit_prompt_template"))
        
        # Get screen resolution and adjust window size
        screen_width = root.winfo_screenwidth()
        screen_height = root.winfo_screenheight()
        window_width = int(screen_width * 0.7)
        window_height = int(screen_height * 0.7)
        
        prompt_window.geometry(f"{window_width}x{window_height}")
        prompt_window.resizable(True, True)
        
        # Create main frame
        prompt_frame = tk.Frame(prompt_window, padx=20, pady=20)
        prompt_frame.pack(fill=tk.BOTH, expand=True)
        
        # Prompt text
        prompt_label = tk.Label(prompt_frame, text=get_text("prompt_template"), font=('Arial', 10, 'bold'))
        prompt_label.pack(pady=5)
        
        # Text widget for prompt editing
        prompt_text = tk.Text(prompt_frame, wrap=tk.WORD, font=('Arial', 10))
        prompt_text.pack(fill=tk.BOTH, expand=True, pady=5)
        
        # Insert default prompt
        default_prompt = """You are a real American citizen with the following personal background:
{background_info}
Fully embody this role, combine American cultural background, life experiences, and true feelings to answer the following questionnaire in the first person{supervisor_note}. Response requirements:
1. Strictly select a score based on the given coding standard (only enter a number between {score_range});
2. Add 1-2 sentences to explain the reason after the score. The reason should match your background and American social culture, avoiding emptiness;
3. Answer naturally and colloquially, like an ordinary American chattingâ€”no formal writing or AI tone;
4. For work-related questions, answer based on your occupation and industry if applicable;
5. Do not reveal you are a simulated role, and never say phrases like "as an AI" or "according to the setting";
6. Only answer based on the current task, do not reference any previous responses.
Question: {question_stem}
Coding Standard: {coding_standard}
Please answer directly without additional formatting."""
        prompt_text.insert(tk.END, default_prompt)
        
        # Button frame
        button_frame = tk.Frame(prompt_frame, pady=10)
        button_frame.pack(fill=tk.X)
        
        def save_prompt():
            # Get the edited prompt
            edited_prompt = prompt_text.get(1.0, tk.END).strip()
            # Here you could save the prompt to a file or update a global variable
            print("Prompt updated:")
            print(edited_prompt)
            # Close the window
            prompt_window.destroy()
        
        save_button = tk.Button(button_frame, text=get_text("save"), command=save_prompt, font=('Arial', 10, 'bold'), width=15)
        save_button.pack(side=tk.RIGHT, padx=5)
        
        cancel_button = tk.Button(button_frame, text=get_text("cancel"), command=prompt_window.destroy, font=('Arial', 10), width=10)
        cancel_button.pack(side=tk.RIGHT, padx=5)
    
    # ---------------- Submit Button ----------------
    def submit():
        # Validate inputs
        if not questionnaire_file_var.get():
            messagebox.showerror(get_text("error"), get_text("error_no_questionnaire"))
            return
        if not subject_file_var.get():
            messagebox.showerror(get_text("error"), get_text("error_no_subject"))
            return
        if not output_dir_var.get():
            messagebox.showerror(get_text("error"), get_text("error_no_output"))
            return
        
        # Close window and return values
        root.destroy()
        
    # Button frame
    button_frame = tk.Frame(main_frame, pady=10)
    button_frame.pack(fill=tk.X)
    
    # Prompt edit button
    tk.Button(button_frame, text=get_text("edit_prompt_template"), command=edit_prompt, font=('Arial', 10), width=15).pack(side=tk.LEFT, padx=5)
    
    # Submit button
    tk.Button(button_frame, text=get_text("start_processing"), command=submit, font=('Arial', 10, 'bold'), width=20).pack(side=tk.RIGHT, padx=5)
    
    # Run the GUI
    root.mainloop()
    
    # Return all settings
    return {
        'api_key': api_key_var.get(),
        'base_url': base_url_var.get(),
        'model_name': model_name_var.get(),
        'random_order': random_order_var.get(),
        'max_consecutive': max_consecutive_var.get(),
        'token_limit': token_limit_var.get(),
        'max_tokens': max_tokens_var.get(),
        'min_age': min_age_var.get(),
        'max_age': max_age_var.get(),
        'column_strategy': column_strategy_var.get(),
        'questionnaire_file': questionnaire_file_var.get(),
        'subject_file': subject_file_var.get(),
        'output_dir': output_dir_var.get(),
        'output_format': output_format_var.get(),
        'output_filename': output_filename_var.get()
    }

# ---------------- Questionnaire File Parser ----------------
def parse_questionnaire_file(file_path, token_limit=4000):
    """Parse questionnaire file based on file type"""
    file_ext = os.path.splitext(file_path)[1].lower()
    
    if file_ext in ['.xlsx', '.xls', '.csv']:
        return parse_excel_csv_questionnaire(file_path)
    elif file_ext == '.docx':
        return parse_word_questionnaire(file_path, token_limit)
    else:
        messagebox.showerror("é”™è¯¯", f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
        return None

def parse_excel_csv_questionnaire(file_path):
    """Parse Excel/CSV questionnaire file"""
    try:
        # Determine file type and read accordingly
        file_ext = os.path.splitext(file_path)[1].lower()
        if file_ext == '.csv':
            df = pd.read_csv(file_path, encoding='utf-8-sig')
        else:
            df = pd.read_excel(file_path)
        
        # Get column names based on current language
        column_names = get_column_names()
        
        # Check for both Chinese and English column names
        chinese_cols = ['é¢˜ç›®ID', 'é¢˜ç›®æ‰€å±ç»´åº¦', 'é¢˜ç›®å†…å®¹', 'è®¡åˆ†æ ‡å‡†']
        english_cols = ['Question ID', 'Dimension', 'Question Content', 'Scoring Standard']
        
        # Determine which set of column names exists in the file
        if all(col in df.columns for col in chinese_cols):
            # Chinese column names found
            col_mapping = dict(zip(chinese_cols, [column_names['question_id'], column_names['dimension'], 
                                                column_names['question_content'], column_names['scoring_standard']]))
        elif all(col in df.columns for col in english_cols):
            # English column names found
            col_mapping = dict(zip(english_cols, [column_names['question_id'], column_names['dimension'], 
                                                column_names['question_content'], column_names['scoring_standard']]))
        else:
            # Neither complete set found, check individual columns
            missing_cols = []
            for chinese_col, english_col in zip(chinese_cols, english_cols):
                if chinese_col not in df.columns and english_col not in df.columns:
                    missing_cols.append(f"{chinese_col} / {english_col}")
            
            if missing_cols:
                messagebox.showerror(get_text("error"), f"é—®å·æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing_cols)}")
                return None
            
            # Create mapping for available columns
            col_mapping = {}
            for chinese_col, english_col in zip(chinese_cols, english_cols):
                if chinese_col in df.columns:
                    col_mapping[chinese_col] = column_names[chinese_cols.index(chinese_col)]
                elif english_col in df.columns:
                    col_mapping[english_col] = column_names[english_cols.index(english_col)]
        
        # Validate data integrity
        invalid_rows = []
        for idx, row in df.iterrows():
            row_num = idx + 2  # Excel rows start at 1, plus header
            missing_values = []
            for col in col_mapping.keys():
                if pd.isna(row[col]) or str(row[col]).strip() == '':
                    missing_values.append(col)
            if missing_values:
                invalid_rows.append(f"Row {row_num}: Missing {', '.join(missing_values)}")
        
        if invalid_rows:
            error_msg = "Found invalid rows:\n" + "\n".join(invalid_rows)
            messagebox.showerror(get_text("error"), error_msg)
            return None
        
        # Parse questions
        questions = []
        for idx, row in df.iterrows():
            # Use column mapping to get correct column names
            question_id = str(row[list(col_mapping.keys())[0]]).strip()
            dimension = str(row[list(col_mapping.keys())[1]]).strip()
            stem = str(row[list(col_mapping.keys())[2]]).strip()
            coding = str(row[list(col_mapping.keys())[3]]).strip()
            
            # Determine reverse coding (check if '(R)' is in stem)
            reverse_coded = '(R)' in stem or '(åå‘)' in stem
            if reverse_coded:
                # Remove (R) marker from stem
                stem = stem.replace('(R)', '').replace('(åå‘)', '').strip()
            
            # Determine score range from coding
            score_range = (1, 5)  # Default
            if '7' in coding:
                score_range = (1, 7)
            
            questions.append({
                "question_id": question_id,
                "dimension": dimension,
                "stem": stem,
                "coding": coding,
                "reverse_coded": reverse_coded,
                "score_range": score_range
            })
        
        print(f"Successfully parsed {len(questions)} questions from Excel/CSV file")
        return questions
        
    except Exception as e:
        messagebox.showerror(get_text("error"), f"è§£æé—®å·æ–‡ä»¶å¤±è´¥: {str(e)}")
        print(f"Error parsing Excel/CSV file: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def parse_word_questionnaire(file_path, token_limit=4000):
    """Parse Word questionnaire file"""
    try:
        doc = Document(file_path)
        full_text = []
        
        # Extract all text from the document
        for para in doc.paragraphs:
            text = para.text.strip()
            if text:
                full_text.append(text)
        
        # Join all text into a single string
        document_text = '\n'.join(full_text)
        
        print(f"\n=== Wordæ–‡æ¡£è§£æè°ƒè¯•ä¿¡æ¯ ===")
        print(f"è¯»å–åˆ° {len(full_text)} è¡Œæ–‡æœ¬")
        
        # Split document into sections based on dimension headers
        # Look for patterns like "Emotional Abuse:", "Emotional Neglect:", etc.
        sections = []
        current_section = []
        dimension_names = []
        
        # å¸¸è§ç»´åº¦åç§°åˆ—è¡¨ï¼ˆç”¨äºåŠ å¼ºè¯†åˆ«ï¼‰
        known_dimensions = [
            'Emotional Abuse',
            'Emotional Neglect', 
            'Supervisory Support',
            'Perceived Control',
            'Personal Mastery',
            'Perceived Constraints',
            'Job Insecurity'
        ]
        
        print(f"\nå¼€å§‹è¯†åˆ«ç»´åº¦æ ‡é¢˜...")
        for line_idx, line in enumerate(full_text):
            # Check if this line is a dimension header
            is_dimension = False
            
            # Check if line ends with colon (allowing spaces before colon) and isn't a known non-dimension line
            # å¯¹ç©ºæ ¼æ›´åŠ å®½å®¹ï¼Œå…è®¸å†’å·å‰åæœ‰ç©ºæ ¼ï¼ŒåŒæ—¶æ”¯æŒå…¨è§’å†’å·
            stripped_line = line.strip()
            # æ£€æŸ¥æ˜¯å¦ä»¥å†’å·ç»“å°¾ï¼ˆæ”¯æŒåŠè§’å’Œå…¨è§’å†’å·ï¼‰
            ends_with_colon = stripped_line.endswith(':') or stripped_line.endswith('ï¼š')
            # æ£€æŸ¥æ˜¯å¦ä¸æ˜¯éç»´åº¦è¡Œ
            is_not_non_dimension = not any(prefix in line for prefix in ['Items:', 'Question', 'Coding:', 'Scaling:', 'Scoring Key:'])
            # æ£€æŸ¥æ˜¯å¦ä¸æ˜¯ç©ºè¡Œ
            is_not_empty = len(stripped_line) > 0
            # æ£€æŸ¥æ˜¯å¦ä¸æ˜¯åªæœ‰å†’å·çš„è¡Œ
            is_not_only_colon = not (stripped_line == ':' or stripped_line == 'ï¼š')
            
            if ends_with_colon and is_not_non_dimension and is_not_empty and is_not_only_colon:
                is_dimension = True
                print(f"  è¡Œ {line_idx+1}: è¯†åˆ«ä¸ºç»´åº¦ï¼ˆå†’å·ç»“å°¾ï¼‰: '{line}'")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥çš„ç»´åº¦åç§°ï¼ˆå³ä½¿ä¸å¸¦å†’å·ï¼‰
            else:
                # åªæœ‰å½“è¡Œé•¿åº¦è¾ƒçŸ­ä¸”çœ‹èµ·æ¥åƒç»´åº¦æ ‡é¢˜æ—¶æ‰æ£€æŸ¥
                # é¿å…æŠŠåŒ…å«"Personal Mastery"çš„é•¿æè¿°è¡Œä¹Ÿè¯†åˆ«ä¸ºç»´åº¦
                if len(stripped_line) < 50:  # é™åˆ¶è¡Œé•¿åº¦ï¼Œé¿å…è¯†åˆ«æè¿°æ€§æ–‡å­—
                    for known_dim in known_dimensions:
                        if known_dim.lower() in stripped_line.lower():
                            # ç¡®ä¿ä¸æ˜¯codingã€scalingç­‰è¡Œ
                            if not any(prefix in line for prefix in ['Items:', 'Question', 'Coding:', 'Scaling:', 'Scoring Key:']):
                                is_dimension = True
                                print(f"  è¡Œ {line_idx+1}: è¯†åˆ«ä¸ºç»´åº¦ï¼ˆå·²çŸ¥åç§°ï¼‰: '{line}' (åŒ¹é…: {known_dim})")
                                break
            
            if is_dimension:
                if current_section:
                    sections.append(current_section)
                current_section = [line]
                # Extract dimension name
                # å¤„ç†åŠè§’å’Œå…¨è§’å†’å·
                dim_name = line.rstrip(':').rstrip('ï¼š').strip()
                # Remove trailing "scale" or "Scale" if present
                dim_name = re.sub(r'\s*(scale|Scale)$', '', dim_name, flags=re.IGNORECASE)
                # Ensure consistent spacing
                dim_name = ' '.join(dim_name.split())
                # ç‰¹æ®Šå¤„ç†å¸¸è§ç»´åº¦åç§°ï¼Œç¡®ä¿æ­£ç¡®è¯†åˆ«
                common_dimensions = {
                    'Emotional Abuse': 'Emotional Abuse',
                    'Emotional Neglect': 'Emotional Neglect',
                    'Supervisory Support': 'Supervisory Support',
                    'Perceived Control': 'Perceived Control',
                    'Personal Mastery': 'Personal Mastery',
                    'Perceived Constraints': 'Perceived Constraints',
                    'Job Insecurit': 'Job Insecurity',
                    'Job Insecurity': 'Job Insecurity'
                }
                # æ ‡å‡†åŒ–ç»´åº¦åç§°
                if dim_name in common_dimensions:
                    dim_name = common_dimensions[dim_name]
                # ä¿®å¤å¸¸è§æ‹¼å†™é”™è¯¯
                if dim_name == 'Job Insecurit':
                    dim_name = 'Job Insecurity'
                # å¦‚æœç»´åº¦åç§°ä¸åœ¨æ˜ å°„è¡¨ä¸­ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ–‡å­—éƒ¨åˆ†
                # ç¡®ä¿ç»´åº¦åç§°ä¸ä¸ºç©º
                if not dim_name:
                    dim_name = f"ç»´åº¦{len(dimension_names) + 1}"
                dimension_names.append(dim_name)
            else:
                current_section.append(line)
        
        # Add the last section
        if current_section:
            sections.append(current_section)
        
        print(f"\nè¯†åˆ«åˆ° {len(sections)} ä¸ªsection")
        print(f"è¯†åˆ«åˆ°çš„ç»´åº¦åç§°: {dimension_names}")
        
        if not sections:
            messagebox.showerror("é”™è¯¯", "Wordæ–‡ä»¶ä¸­æœªæ‰¾åˆ°é—®å·ç»´åº¦")
            return None
        
        # Parse each section
        questions = []
        dimension_counter = {}
        
        for section_idx, section in enumerate(sections):
            section_text = '\n'.join(section)
            dimension = dimension_names[section_idx] if section_idx < len(dimension_names) else f"ç»´åº¦{section_idx+1}"
            print(f"\nå¤„ç†Section {section_idx+1}, ç»´åº¦: {dimension}")
            print(f"Sectionå†…å®¹è¡Œæ•°: {len(section)}")
            
            # Extract coding information with enhanced patterns
            # æŒ‰ç…§ç”¨æˆ·è¦æ±‚ï¼šè®¡åˆ†è§„åˆ™è¯†åˆ«ä¸º'Coding:(åè¿æ¥çš„ä¸€å¥è¯).'
            coding_patterns = [
                r'Coding:\s*(.*?)\.',  # ç”¨æˆ·è¦æ±‚çš„æ ¼å¼ï¼šCoding: åè¿æ¥çš„ä¸€å¥è¯ï¼Œä»¥å¥å·ç»“å°¾
                r'(?:Scoring Key|Scoring):\s*(.*?)\.',  # å…¶ä»–è®¡åˆ†è§„åˆ™æ ¼å¼
                r'(?:Responses are obtained using a|Scoring Key:)\s*(.*?)(?:\n|$)',
                r'(?:1 = |Strongly agree;).*?(?:\n|$)',  # Additional patterns for coding
                r'(?:Scoring Key:|Coding:).*?(?:1.*?5|1.*?7)(?:\n|$)'
            ]
            
            coding = "1-5 Likert scale"  # Default
            for pattern in coding_patterns:
                coding_match = re.search(pattern, section_text, re.DOTALL | re.IGNORECASE)
                if coding_match:
                    coding = coding_match.group(1).strip() if len(coding_match.groups()) > 0 else coding_match.group(0).strip()
                    break
            
            # Determine score range with enhanced logic
            score_range = (1, 5)  # Default
            if '7' in coding:
                score_range = (1, 7)
            elif '6' in coding:
                score_range = (1, 6)
            elif '4' in coding:
                score_range = (1, 4)
            
            # Extract questions with enhanced regex patterns
            # æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼šé¢˜ç›®å¿…é¡»åŒ…å«æ¥å›åŒå¼•å·ï¼Œä¾‹å¦‚ï¼š4. "People in my family felt close to each other." (R)
            # å¯¹ç©ºæ ¼æ›´åŠ å®½å®¹ï¼Œå…è®¸æœ€å¤š3ä¸ªç©ºæ ¼
            question_patterns = [
                # æ ‡å‡†æ•°å­—ç¼–å· + åŒå¼•å·é¢˜ç›®ï¼š1. "Question text" (R)
                r'(\d+)\.\s{0,3}"(.*?)"\s{0,3}(?:\(R\))?\s{0,3}(?:\n|$)',
                # å¸¦æ˜Ÿå·çš„æ•°å­—ç¼–å· + åŒå¼•å·é¢˜ç›®ï¼š*1. "Question text" (R)
                r'\*?(\d+)\s{0,3}[.:]*\s{0,3}"(.*?)"\s{0,3}(?:\(R\))?\s{0,3}(?:\n|$)',
                # é¡¹ç›®ç¬¦å· + åŒå¼•å·é¢˜ç›®ï¼šâ€¢ "Question text" (R)
                r'â€¢\s{0,3}"(.*?)"\s{0,3}(?:\(R\))?\s{0,3}(?:\n|$)',
                # æ•°å­— + ç©ºæ ¼ + åŒå¼•å·é¢˜ç›®ï¼š1 "Question text" (R)
                r'(\d+)\s{0,3}"(.*?)"\s{0,3}(?:\(R\))?\s{0,3}(?:\n|$)',
                # å‰å¯¼æ˜Ÿå· + åŒå¼•å·é¢˜ç›®ï¼š*"Question text" (R)
                r'\*\s{0,3}"(.*?)"\s{0,3}(?:\(R\))?\s{0,3}(?:\n|$)'
            ]
            
            for pattern in question_patterns:
                question_matches = re.findall(pattern, section_text, re.DOTALL)
                if question_matches:
                    for match in question_matches:
                        if len(match) == 2:
                            # Numbered question with quotes
                            q_num, q_text = match
                            # Clean up question number
                            q_num = re.sub(r'[^0-9]', '', q_num)
                            if q_num:
                                q_num = int(q_num)
                            else:
                                continue  # Skip if no valid number
                        else:
                            # Bullet point or other format question with quotes
                            if isinstance(match, tuple):
                                q_text = match[0]
                            else:
                                q_text = match
                            # Generate question number based on position
                            if dimension not in dimension_counter:
                                q_num = 1
                            else:
                                q_num = dimension_counter[dimension] + 1
                        
                        q_text = q_text.strip()
                        # æ³¨æ„ï¼šç”±äºæ­£åˆ™è¡¨è¾¾å¼å·²ç»åªæ•è·åŒå¼•å·å†…çš„æ–‡æœ¬ï¼Œæ‰€ä»¥ä¸éœ€è¦å†ç§»é™¤å¼•å·
                        # Remove any leading asterisks (if any)
                        q_text = q_text.lstrip('*').strip()
                        
                        # Check for reverse coding (more robust)
                        reverse_coded = False
                        if '(R)' in q_text:
                            reverse_coded = True
                            q_text = q_text.replace('(R)', '').strip()
                        elif 'åå‘' in q_text:
                            reverse_coded = True
                            q_text = q_text.replace('åå‘', '').strip()
                        
                        # Generate question ID
                        if dimension not in dimension_counter:
                            dimension_counter[dimension] = 1
                        else:
                            dimension_counter[dimension] += 1
                        
                        # Create a short dimension code for question ID
                        dim_code = ''.join([word[0].upper() for word in dimension.split() if word])[:3]
                        question_id = f"{dim_code}_{dimension_counter[dimension]}"
                        
                        # Skip empty questions and non-question lines
                        non_question_markers = ['Items:', 'Question', 'Coding:', 'Scaling:', 'Scoring Key:', 'æˆ–']
                        if q_text and len(q_text) > 3 and not any(marker in q_text for marker in non_question_markers):
                            questions.append({
                                "question_id": question_id,
                                "dimension": dimension,
                                "stem": q_text,
                                "coding": coding,
                                "reverse_coded": reverse_coded,
                                "score_range": score_range
                            })
                            # Print debug info
                            print(f"Parsed question: {question_id} - {q_text} (R: {reverse_coded})")
        
        # If no questions found, try alternative parsing approach
        if not questions:
            # Try parsing line by line with improved logic
            current_dimension = "Unknown"
            current_coding = "1-5 Likert scale"
            dimension_counter = {}
            
            for line in full_text:
                # Check for dimension headers
                is_dimension = False
                stripped_line = line.strip()
                
                if line.endswith(':') and not any(prefix in line for prefix in ['Items:', 'Question', 'Coding:', 'Scaling:', 'Scoring Key:']):
                    is_dimension = True
                else:
                    # ä½¿ç”¨known_dimensionsæ£€æŸ¥å·²çŸ¥ç»´åº¦
                    if len(stripped_line) < 50:
                        for known_dim in known_dimensions:
                            if known_dim.lower() in stripped_line.lower():
                                if not any(prefix in line for prefix in ['Items:', 'Question', 'Coding:', 'Scaling:', 'Scoring Key:']):
                                    is_dimension = True
                                    break
                
                if is_dimension:
                    current_dimension = line.rstrip(':').strip()
                    current_dimension = re.sub(r'\s*(scale|Scale)$', '', current_dimension, flags=re.IGNORECASE)
                    if current_dimension not in dimension_counter:
                        dimension_counter[current_dimension] = 0
                
                # Check for coding information
                elif line.startswith('Coding:'):
                    current_coding = line[7:].strip()
                elif line.startswith('Scoring Key:'):
                    current_coding = line[13:].strip()
                
                # Check for questions
                elif re.match(r'^(\d+)\.|^â€¢|^\*', line):
                    # Extract question text
                    if re.match(r'^(\d+)\.', line):
                        q_match = re.match(r'^(\d+)\.\s*(.*)$', line)
                        if q_match:
                            q_text = q_match.group(2).strip()
                    elif re.match(r'^â€¢', line):
                        # Bullet point question
                        q_text = line[1:].strip()
                    elif re.match(r'^\*', line):
                        # Asterisk question
                        q_text = line[1:].strip()
                    else:
                        # Other format question
                        q_text = line.strip()
                    
                    # Remove quotes if present
                    if q_text.startswith('"') and q_text.endswith('"'):
                        q_text = q_text[1:-1]
                    
                    # Remove any leading asterisks
                    q_text = q_text.lstrip('*').strip()
                    
                    # Check for reverse coding
                    reverse_coded = '(R)' in q_text
                    if reverse_coded:
                        q_text = q_text.replace('(R)', '').strip()
                    elif 'åå‘' in q_text:
                        reverse_coded = True
                        q_text = q_text.replace('åå‘', '').strip()
                    
                    # Generate question number
                    dimension_counter[current_dimension] += 1
                    q_num = dimension_counter[current_dimension]
                    
                    # Create a short dimension code for question ID
                    dim_code = ''.join([word[0].upper() for word in current_dimension.split() if word])[:3]
                    question_id = f"{dim_code}_{q_num}"
                    
                    # Determine score range
                    score_range = (1, 5)  # Default
                    if '7' in current_coding:
                        score_range = (1, 7)
                    
                    # Skip empty questions
                    if q_text:
                        questions.append({
                            "question_id": question_id,
                            "dimension": current_dimension,
                            "stem": q_text,
                            "coding": current_coding,
                            "reverse_coded": reverse_coded,
                            "score_range": score_range
                        })
        
        # If still no questions found, try LLM-based parsing
        if not questions:
            messagebox.showinfo("æç¤º", "å°è¯•ä½¿ç”¨å¤§æ¨¡å‹è§£æå¤æ‚é—®å·ç»“æ„...")
            questions = parse_questionnaire_with_llm(document_text, token_limit)
        
        if not questions:
            messagebox.showerror("é”™è¯¯", "Wordæ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆé¢˜ç›®")
            return None
        
        print(f"\n=== è§£æç»“æœç»Ÿè®¡ ===")
        print(f"Successfully parsed {len(questions)} questions from Word file")
        
        # æŒ‰ç»´åº¦ç»Ÿè®¡é¢˜ç›®æ•°é‡
        from collections import defaultdict
        dimension_question_count = defaultdict(int)
        for q in questions:
            dimension_question_count[q['dimension']] += 1
        
        print("\nå„ç»´åº¦é¢˜ç›®æ•°é‡:")
        for dim, count in sorted(dimension_question_count.items()):
            print(f"  {dim}: {count} é¢˜")
        
        print("\nå‰5é“é¢˜çš„ç»´åº¦ä¿¡æ¯:")
        for i, q in enumerate(questions[:5], 1):
            print(f"  {i}. [{q['question_id']}] ç»´åº¦: {q['dimension']}")
        
        return questions
        
    except Exception as e:
        messagebox.showerror("é”™è¯¯", f"è§£æWordé—®å·æ–‡ä»¶å¤±è´¥: {str(e)}")
        print(f"Error parsing Word file: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def parse_questionnaire_with_llm(document_text, token_limit=4000):
    """Parse questionnaire using LLM for complex structures"""
    try:
        # Prepare prompt for LLM
        prompt = f"""You are an expert in questionnaire analysis. Please parse the following questionnaire text and extract:
1. Dimensions (questionnaire sections)
2. Questions within each dimension
3. Coding standards (scoring scales)
4. Reverse-coded items (marked with (R))

Return the result as a JSON array of objects, where each object has:
- question_id: Unique identifier (e.g., "EA_1" for Emotional Abuse question 1)
- dimension: Dimension name
- stem: Question text (without (R) marker)
- coding: Scoring standard
- reverse_coded: Boolean indicating if reverse-coded
- score_range: Tuple of (min, max) score values

Questionnaire text:
{document_text}

Please return only the JSON array, no other text."""
        
        # Call LLM with token limit
        response = call_llm(prompt, max_tokens=token_limit)
        
        # Parse JSON response
        import json
        # Extract JSON from response
        json_match = re.search(r'\[\s*\{[\s\S]*\}\s*\]', response)
        if not json_match:
            print("LLM response does not contain valid JSON")
            return None
        
        json_str = json_match.group(0)
        questions = json.loads(json_str)
        
        # Validate and format the result
        formatted_questions = []
        for q in questions:
            # Ensure required fields are present
            if all(key in q for key in ['question_id', 'dimension', 'stem', 'coding']):
                # Set default values for optional fields
                reverse_coded = q.get('reverse_coded', False)
                score_range = q.get('score_range', [1, 5])
                
                formatted_questions.append({
                    "question_id": q['question_id'],
                    "dimension": q['dimension'],
                    "stem": q['stem'],
                    "coding": q['coding'],
                    "reverse_coded": reverse_coded,
                    "score_range": tuple(score_range)
                })
        
        return formatted_questions if formatted_questions else None
        
    except Exception as e:
        print(f"Error parsing questionnaire with LLM: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

# ---------------- Main Process ----------------
def main():
    # å£°æ˜å…¨å±€å˜é‡
    global FATAL_API_ERROR, DASHSCOPE_API_KEY, BASE_URL, MODEL_NAME, MAX_CONSECUTIVE_SAME_DIM
    
    # æ¸…ç†æ‰€æœ‰å¯èƒ½çš„tkinterçª—å£ï¼Œç¡®ä¿å¹²å‡€çš„çŠ¶æ€
    try:
        import tkinter as tk
        # å°è¯•è·å–å¹¶é”€æ¯æ‰€æœ‰é¡¶å±‚çª—å£
        if tk._default_root:
            # éšè—é»˜è®¤æ ¹çª—å£
            tk._default_root.withdraw()
            # é”€æ¯æ‰€æœ‰å­çª—å£
            for widget in tk._default_root.winfo_children():
                try:
                    widget.destroy()
                except:
                    pass
    except Exception as e:
        print(f"æ¸…ç†çª—å£æ—¶å‡ºç°é”™è¯¯: {e}")
        pass
    
    # é‡ç½®å…¨å±€é”™è¯¯æ ‡å¿—
    FATAL_API_ERROR = False
    # 1. Show settings GUI
    settings = show_settings_gui()
    
    # Check if GUI was cancelled
    if not settings['questionnaire_file'] or not settings['subject_file'] or not settings['output_dir']:
        return
    
    # Update global API settings
    DASHSCOPE_API_KEY = settings['api_key']
    BASE_URL = settings['base_url']
    MODEL_NAME = settings['model_name']
    MAX_CONSECUTIVE_SAME_DIM = settings['max_consecutive']
    MAX_TOKENS = settings['max_tokens']
    
    # Re-initialize API client with new settings
    global client
    client = OpenAI(
        api_key=DASHSCOPE_API_KEY,
        base_url=BASE_URL,
    )
    
    # Extract settings
    questionnaire_file = settings['questionnaire_file']
    subject_file = settings['subject_file']
    output_dir = settings['output_dir']
    output_format = settings['output_format']
    output_filename = settings.get('output_filename', 'EasyPsych_Results')
    random_order = settings['random_order']
    token_limit = settings['token_limit']
    max_tokens = settings['max_tokens']
    min_age = settings['min_age']
    max_age = settings['max_age']
    column_strategy = settings['column_strategy']
    
    print(f"Selected questionnaire file: {questionnaire_file}")
    print(f"Selected subject background file: {subject_file}")
    print(f"Selected output directory: {output_dir}")
    print(f"Output filename: {output_filename}")
    print(f"Random question order: {random_order}")
    print(f"Max consecutive same dimension: {MAX_CONSECUTIVE_SAME_DIM}")
    
    # 2. Parse questionnaire file
    questions = parse_questionnaire_file(questionnaire_file, token_limit)
    if not questions:
        messagebox.showerror("é”™è¯¯", "è§£æé—®å·æ–‡ä»¶å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return
    
    # 3. Create output directory
    out_dir = Path(output_dir)
    out_dir.mkdir(parents=True, exist_ok=True)
    
    # 4. Load subject background
    subjects = load_subject_background(subject_file, output_dir, min_age, max_age)
    if subjects == "RETURN_TO_SETTINGS":
        # ç”¨æˆ·é€‰æ‹©è¿”å›è®¾ç½®ç•Œé¢
        return True
    elif not subjects:
        messagebox.showerror("é”™è¯¯", "æœªåŠ è½½åˆ°æœ‰æ•ˆè¢«è¯•ï¼Œç¨‹åºé€€å‡º")
        return
    
    # 3. Iterate over subjects to generate responses
    all_results = []
    failed_records = []  # Record failed questions for later check
    
    # åˆ›å»ºè¿›åº¦æ¡å¼¹çª—
    import tkinter as tk
    from tkinter import ttk
    import time
    
    progress_window = tk.Toplevel()
    progress_window.title("å¤„ç†è¿›åº¦")
    progress_window.geometry("400x150")
    progress_window.resizable(False, False)
    
    # ç¡®ä¿çª—å£åœ¨æœ€å‰é¢
    progress_window.attributes('-topmost', True)
    progress_window.lift()
    
    progress_label = tk.Label(progress_window, text=get_text("progress_ready"), font=('Arial', 10))
    progress_label.pack(pady=20)
    
    progress_bar = ttk.Progressbar(progress_window, orient=tk.HORIZONTAL, length=350, mode='determinate')
    progress_bar.pack(pady=10)
    
    status_label = tk.Label(progress_window, text="", font=('Arial', 8), fg='gray')
    status_label.pack(pady=5)
    
    total_subjects = len(subjects)
    progress_bar['maximum'] = total_subjects
    
    # å…ˆæ›´æ–°ä¸€æ¬¡çª—å£è®©å®ƒæ˜¾ç¤ºå‡ºæ¥
    progress_window.update()
    progress_window.update_idletasks()
    time.sleep(0.1)  # çŸ­æš‚å»¶è¿Ÿç¡®ä¿çª—å£å®Œå…¨æ¸²æŸ“
    
    # æ·»åŠ æ ‡å¿—æ¥è·Ÿè¸ªç¨‹åºæ˜¯å¦æ­£å¸¸å®Œæˆ
    completed_successfully = False
    
    try:
        for i, subject in enumerate(subjects, 1):
            # Check fatal error: stop processing new subjects
            if FATAL_API_ERROR:
                break
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_label.config(text=f"å¤„ç†è¢«è¯• {i}/{total_subjects}")
            status_label.config(text=f"æ­£åœ¨å¤„ç†è¢«è¯• {subject['subject_id']} ({subject['æ€§åˆ«']}, {subject['å¹´é¾„']}å²)")
            progress_bar['value'] = i
            # ä½¿ç”¨update_idletasksæ›´è½»é‡ï¼Œé¿å…å¡é¡¿
            progress_window.update_idletasks()
            
            print(f"\nProcessing subject {subject['subject_id']} ({subject['æ€§åˆ«']}, {subject['å¹´é¾„']} years old)...")
            subject_responses = []
            
            # Get question order based on settings
            if random_order:
                random_question_list = get_random_questions(questions)
                print(f"  Generated random question order (total {len(random_question_list)} questions)")
            else:
                # Use parsed question order (no randomization)
                random_question_list = questions  # ä½¿ç”¨è§£æå¾—åˆ°çš„é—®é¢˜åˆ—è¡¨
                print(f"  Using parsed question order (total {len(random_question_list)} questions)")
            
            # å¹¶å‘å¤„ç†æ‰€æœ‰é—®é¢˜ä»¥æé«˜æ•ˆç‡
            print(f"  å¼€å§‹å¹¶å‘å¤„ç† {len(random_question_list)} ä¸ªé—®é¢˜...")
            
            # å‡†å¤‡APIè®¾ç½®
            api_settings = {
                'max_tokens': max_tokens
            }
            
            # ä¸ºæ¯ä¸ªé—®é¢˜æ·»åŠ éšæœºåºå·
            for idx, question in enumerate(random_question_list, start=1):
                question['random_index'] = idx
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
            max_workers = min(5, len(random_question_list))  # é™åˆ¶å¹¶å‘æ•°ï¼Œé¿å…APIé™åˆ¶
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                # å‡†å¤‡ä»»åŠ¡å‚æ•°
                task_args = [(subject, question, column_strategy, api_settings) 
                            for question in random_question_list]
                
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_question = {executor.submit(process_single_question, args): args 
                                    for args in task_args}
                
                # å¤„ç†å®Œæˆçš„ä»»åŠ¡
                completed_count = 0
                for future in concurrent.futures.as_completed(future_to_question):
                    completed_count += 1
                    args = future_to_question[future]
                    question = args[1]
                    
                    # æ£€æŸ¥è‡´å‘½é”™è¯¯
                    if FATAL_API_ERROR:
                        print(f"  æ£€æµ‹åˆ°è‡´å‘½APIé”™è¯¯ï¼Œåœæ­¢å¤„ç†å‰©ä½™é—®é¢˜")
                        break
                    
                    try:
                        response_record, error_record = future.result()
                        subject_responses.append(response_record)
                        
                        if error_record:
                            failed_records.append(error_record)
                        
                        print(f"  å·²å®Œæˆ {completed_count}/{len(random_question_list)}: {question['question_id']} (çŠ¶æ€: {response_record['ä½œç­”çŠ¶æ€']})")
                        
                    except Exception as e:
                        print(f"  å¤„ç†é—®é¢˜ {question['question_id']} æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                        
                        # æ·»åŠ å¤±è´¥è®°å½•
                        failed_response = {
                            "è¢«è¯•ID": subject['subject_id'],
                            "æ€§åˆ«": subject['æ€§åˆ«'],
                            "å¹´é¾„": subject['å¹´é¾„'],
                            "éšæœºé¢˜ç›®åºå·": question.get('random_index', 0),
                            "åŸå§‹é¢˜ç›®ID": question['question_id'],
                            "ç»´åº¦": question['dimension'],
                            "é¢˜ç›®å†…å®¹ï¼ˆè‹±æ–‡ï¼‰": question['stem'],
                            "è®¡åˆ†æ ‡å‡†ï¼ˆè‹±æ–‡ï¼‰": question['coding'],
                            "æ˜¯å¦åå‘è®¡åˆ†": question['reverse_coded'],
                            "åŸå§‹å“åº”ï¼ˆè‹±æ–‡ï¼‰": f"PROCESSING_ERROR: {str(e)}",
                            "æå–åˆ†æ•°": None,
                            "æœ€ç»ˆå¾—åˆ†": None,
                            "å›ç­”ç†ç”±ï¼ˆè‹±æ–‡ï¼‰": "Processing error",
                            "ä½œç­”çŠ¶æ€": "å¤±è´¥"
                        }
                        
                        # æ·»åŠ æ‰€æœ‰å…¶ä»–èƒŒæ™¯æ–‡ä»¶å­—æ®µ
                        for key, value in subject.items():
                            if key not in ['subject_id', 'æ€§åˆ«', 'å¹´é¾„']:
                                failed_response[key] = value
                        
                        subject_responses.append(failed_response)
                        failed_records.append({
                            "è¢«è¯•ID": subject['subject_id'],
                            "é¢˜ç›®ID": question['question_id'],
                            "é”™è¯¯åŸå› ": str(e)
                        })
            
            # Calculate dimension scores for the subject
            scale_scores = calculate_scale_scores(subject_responses)
            # Merge dimension scores into each response
            for resp in subject_responses:
                resp.update(scale_scores)
            # Add to total results
            all_results.extend(subject_responses)
        
        # æ‰€æœ‰è¢«è¯•å¤„ç†å®Œæˆï¼Œè®¾ç½®æ ‡å¿—
        completed_successfully = True
    
    except KeyboardInterrupt:
        print("\nğŸ”´ Program interrupted by user (Ctrl+C)")
    finally:
        # å…³é—­è¿›åº¦æ¡å¼¹çª—
        try:
            progress_window.destroy()
        except:
            pass
        
        # æ˜¾ç¤ºæˆåŠŸæˆ–é”™è¯¯å¼¹çª—
        from tkinter import messagebox
        
        if FATAL_API_ERROR:
            print(f"\nğŸ”´ Program terminated due to fatal API error: {FATAL_ERROR_MSG}")
            print("ğŸ”´ Please resolve the API issue (e.g., recharge Alibaba Cloud account) and restart the program.")
            # ä¿å­˜ä¸­æ–­ç»“æœ
            save_current_results(all_results, failed_records, out_dir, output_format, is_final=False, output_filename=output_filename)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯APIé”™è¯¯ç›‘æ§è§¦å‘çš„åœæ­¢
            if "è¿ç»­APIè°ƒç”¨å¤±è´¥æ¬¡æ•°è¿‡å¤š" in FATAL_ERROR_MSG:
                error_message = f"{get_text('error_api_fatal')}:\n{FATAL_ERROR_MSG}\n\n{get_text('error_check_balance')}\n\n{get_text('error_check_api_input')}"
                messagebox.showerror(get_text("error"), error_message)
            else:
                messagebox.showerror(get_text("error"), f"{get_text('error_api_fatal')}:\n{FATAL_ERROR_MSG}\n\n{get_text('error_check_balance')}\n\n{get_text('error_check_api_input')}")
                
        elif not all_results:
            messagebox.showerror(get_text("error"), get_text("error_no_valid_subjects"))
        elif not completed_successfully:
            # ç¨‹åºè¢«ä¸­æ–­æˆ–å‡ºé”™
            print("\nğŸ”´ Program did not complete successfully")
            save_current_results(all_results, failed_records, out_dir, output_format, is_final=False, output_filename=output_filename)
            messagebox.showwarning(get_text("warning"), get_text("warning_incomplete"))
        else:
            # ç¨‹åºæ­£å¸¸å®Œæˆ
            print("\nâœ… Program exited safely (all current results saved)")
            # ä¿å­˜æœ€ç»ˆç»“æœ
            save_current_results(all_results, failed_records, out_dir, output_format, is_final=True, output_filename=output_filename)
            output_file = out_dir / f"{output_filename}.{output_format}"
            
            # æ„å»ºæˆåŠŸä¿¡æ¯
            result_text = f"{get_text('success_completed')}\n\n{get_text('success_subjects_processed', count=len(subjects))}\n{get_text('success_results_generated', count=len(all_results))}\n\n{get_text('success_file_saved')}\n{output_file}"
            
            # ä½¿ç”¨messagebox.showinfoæ˜¾ç¤ºä¿¡æ¯ï¼Œç„¶åç”¨askyesnoè¯¢é—®ä¸‹ä¸€æ­¥
            messagebox.showinfo(get_text("success"), result_text)
            
            # è¯¢é—®ç”¨æˆ·æ˜¯å¦è¦è¿”å›è®¾ç½®ç•Œé¢
            answer = messagebox.askyesno(get_text("next_step"), get_text("return_to_settings"))
            
            if answer:
                # ç”¨æˆ·é€‰æ‹©è¿”å›è®¾ç½®
                # è¿”å›Trueè¡¨ç¤ºéœ€è¦é‡æ–°è¿è¡Œ
                return True
            else:
                # ç”¨æˆ·é€‰æ‹©é€€å‡ºç¨‹åº
                return False
    
    # å¦‚æœç¨‹åºæ²¡æœ‰æ­£å¸¸å®Œæˆæˆ–è€…ç”¨æˆ·ä¸è¿”å›è®¾ç½®ï¼Œè¿”å›False
    return False

if __name__ == "__main__":
    # Create necessary directories for application packaging
    app_dir = Path(os.path.dirname(os.path.abspath(__file__)))
    icon_dir = app_dir / "icons"
    icon_dir.mkdir(exist_ok=True)
    
    # Create a placeholder for icon file
    icon_placeholder = icon_dir / "app_icon.png"
    if not icon_placeholder.exists():
        with open(icon_placeholder, 'w') as f:
            f.write("# App icon placeholder\n# Replace this file with your actual app icon (PNG format)")
    
    print(f"Created icon directory: {icon_dir}")
    print(f"Icon placeholder created at: {icon_placeholder}")
    
    # PyInstaller is only needed for building, not for running
    # åªåœ¨æ„å»ºæ—¶éœ€è¦ï¼Œè¿è¡Œæ—¶ä¸éœ€è¦å¯¼å…¥
    # Note: PyInstaller import is commented out to avoid Pylance warnings
    # It will be imported dynamically only when needed for building
    # def check_pyinstaller():
    #     try:
    #         # å°è¯•å¯¼å…¥ï¼Œä½†å³ä½¿å¤±è´¥ä¹Ÿä¸å½±å“è¿è¡Œ
    #         import PyInstaller
    #         print("PyInstaller is installed (for building)")
    #     except ImportError:
    #         # é™é»˜å¤„ç†ï¼Œä¸æ‰“å°ä»»ä½•ä¿¡æ¯
    #         pass
    
    # Only check PyInstaller if needed
    # check_pyinstaller()  # Uncomment if you want to check PyInstaller installation

    # è‹¥ä¸ºæœ¬åœ°è°ƒè¯•æ¨¡å¼ï¼Œç”Ÿæˆä¸€ä¸ªå°çš„å—è¯•è€… Excel ä¾›è„šæœ¬è¯»å–ï¼ˆé¿å…ä¾èµ–å¤–éƒ¨æ–‡ä»¶ï¼‰
    if 'DEBUG_MODE' in globals() and DEBUG_MODE:
        test_file = Path(OUTPUT_DIR) / "debug_test_subjects.xlsx"
        if not test_file.exists():
            df_test = pd.DataFrame([
                {
                    'æ€§åˆ«': 'å¥³', 'å¹´é¾„': 30, 'æœ€é«˜æ•™è‚²æ°´å¹³': 'å­¦å£«åŠä»¥ä¸Šå­¦ä½',
                    'èŒä¸š': 'ä¸“ä¸šæŠ€æœ¯ç±»', 'è¡Œä¸š': 'ä¸“ä¸šåŠç›¸å…³æœåŠ¡', 'å®¶åº­å¹´æ€»æ”¶å…¥': '$50,000â€“$74,999'
                },
                {
                    'æ€§åˆ«': 'ç”·', 'å¹´é¾„': 45, 'æœ€é«˜æ•™è‚²æ°´å¹³': 'é«˜ä¸­æ¯•ä¸š',
                    'èŒä¸š': 'æœåŠ¡è¡Œä¸š', 'è¡Œä¸š': 'ä¸ªäººæœåŠ¡', 'å®¶åº­å¹´æ€»æ”¶å…¥': '$25,000â€“$49,999'
                }
            ])
            df_test.to_excel(test_file, index=False, engine='openpyxl')
            print(f"âš™ï¸ DEBUG: ç”Ÿæˆæµ‹è¯•å—è¯•è€…æ–‡ä»¶ -> {test_file}")
        # è¦†ç›–å…¨å±€ SUBJECT_BACKGROUND_FILE æŒ‡å‘æµ‹è¯•æ–‡ä»¶
        SUBJECT_BACKGROUND_FILE = str(test_file)

    # Run main process in a loop until user chooses to exit
    while True:
        try:
            should_restart = main()
            if not should_restart:
                break
        except KeyboardInterrupt:
            print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
            break
        except Exception as e:
            print(f"\nç¨‹åºå‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            break